# Withforce MES 시스템 개선안 v2.0

**문서 버전:** v2.0
**작성일:** 2025-11-10
**문서 유형:** 시스템 요구사항 명세서

---

## 문서 요약

### 프로젝트 개요

**목적:** Withforce 웨어러블 로봇 생산 라인에 MES(제조실행시스템)를 도입하여 완벽한 제품 추적성과 실시간 생산 모니터링 체계를 구축합니다.

**핵심 기능:**
- LOT 및 시리얼 번호 기반 제품 추적
- 8개 공정별 착공/완공 관리
- 실시간 생산 현황 대시보드
- 품질 데이터 자동 수집 및 분석

### 주요 수치

| 항목 | 수치 |
|------|------|
| **동시 사용자** | 100명 (작업자 70명 + 관리자 30명) |
| **일일 트랜잭션** | 약 50,000건 |
| **생산 대상** | LOT당 100대, 일일 약 100대 |

### 기술 스택

| 계층 | 기술 |
|------|------|
| **백엔드** | Python 3.11, FastAPI, PostgreSQL 15 |
| **프론트엔드** | PyQt5 (작업 PC), React 18 (관리자 대시보드) |
| **인프라** | Ubuntu 22.04, Nginx, Docker |
| **기타** | File Watcher, Zebra 프린터, 바코드 스캐너 |

### 문서 구성

1. **프로젝트 개요** - 배경, 범위, 사용자 정의
2. **제품 및 공정 현황 (AS-IS)** - 현재 생산 공정 및 문제점 분석
3. **MES 요구사항 (TO-BE)** - 기능 요구사항, 데이터 인터페이스, 검수 항목
4. **시스템 아키텍처** - 기술 스택, 성능 설계, AWS 마이그레이션 전략
5. **데이터 설계** - ERD, 데이터베이스 스키마, 번호 체계
6. **개발 및 투자 계획** - 일정, 팀 구성, 투자 비용, ROI, 리스크 관리
7. **부록** - 용어 정의, 버전 이력, 참고 자료

---

## 1. 프로젝트 개요

### 1.1 프로젝트 배경

Withforce는 산업용/농업용 허리 보조 로봇을 생산하고 있으며, 현재 생산 공정 전반에 걸친 데이터 수집 및 추적 체계가 미흡한 상황입니다.

제품 불량 발생 시 원인 파악이 어렵고, 실시간 생산 현황 모니터링이 불가능하여 효율적인 생산 관리에 어려움을 겪고 있습니다.

본 프로젝트는 MES(제조실행시스템) 도입을 통해 완벽한 제품 추적성을 확보하고, 실시간 생산 모니터링 및 데이터 기반 품질 관리 체계를 구축하는 것을 목표로 합니다.

### 1.2 프로젝트 범위

#### 1.2.1 Phase 1: MVP (Minimum Viable Product)

**목표:** 핵심 MES 기능 구현을 통한 기본 추적성 확보 및 생산 현황 가시화

**1. LOT 및 시리얼 번호 관리** (Priority: P0 - Critical)
- LOT 생성 및 상태 관리 (CREATED → IN_PROGRESS → COMPLETED → CLOSED)
- 자동 LOT 번호 발급 (형식: WF-KR-YYMMDDX-nnn)
- LOT 바코드 라벨 출력 (Zebra 프린터 연동)
- 시리얼 번호 자동 생성 및 발급 (Label Printing 공정)
- 시리얼 번호 바코드 라벨 출력
- 라벨 재출력 기능 (손상/분실 시)

**2. 공정별 착공/완공 관리** (Priority: P0 - Critical)
- 8개 공정별 착공 등록 (바코드 스캔 기반)
- 공정 순서 제어 (이전 공정 미완료 시 착공 불가)
- 완공 데이터 수집 (JSON 파일 기반 File Watcher)
- 공정별 측정 데이터 저장 (온도, 변위, 힘, 부품 LOT 등)
- 합격/불합격 판정 자동 처리
- 작업자 및 작업 시간 기록

**3. 실시간 생산 현황 대시보드** (Priority: P1 - High)
- 금일 생산 현황 (착공/완공/불량 건수)
- LOT별 진행 상태 및 공정별 현황
- 공정별 병목 구간 시각화
- LOT 상세 조회 (공정 이력, 시리얼 목록)
- 시리얼 번호 기반 전체 이력 추적
- 불량 현황 및 통계

**4. 기본 추적성 기능** (Priority: P1 - High)
- 시리얼 번호 → LOT → 공정 이력 추적
- 공정별 작업 데이터 조회
- 사용 부품 LOT 추적 (모선, 링크 등)
- 작업자 이력 조회
- 불량 원인 추적

**산출물:**
- 프론트엔드 앱 (PyQt5) - 작업 PC용
- 관리자 대시보드 (React) - 웹 브라우저
- 백엔드 API 서버 (FastAPI)
- PostgreSQL 데이터베이스
- 시스템 운영 매뉴얼

**배포 옵션:**

본 시스템은 **두 가지 배포 방식** 중 선택 가능하도록 설계되었습니다:

| 옵션 | 설명 | 초기 투자 | 월 운영비 | 추천 대상 |
|------|------|----------|----------|----------|
| **Option A: 온프레미스** | 자체 서버 구축 | 4,985만원 | 113만원 | 데이터 보안 중시, 장기 운영 |
| **Option B: 클라우드** | Railway 또는 AWS | 1,805만원 | 26-350만원 | 빠른 시작, 확장성 중시 |

> **상세 비교:** 배포 옵션별 장단점, 비용, 아키텍처는 **4.1 배포 옵션 비교** 참조

**검수 기준:**
- LOT 생성 시간: 30초 이내
- 착공 API 응답 시간: 1초 이내
- 대시보드 로딩 시간: 3초 이내
- 시리얼 추적 조회 시간: 5초 이내
- 동시 사용자 20명 부하 테스트 통과

**명시적 제외 항목 (Scope Out):**
- 서버 이중화 (HA)
- 고급 통계 분석 (SPC, OEE)
- ERP 시스템 연동
- AI 기반 불량 예측
- 클라우드 배포

---

#### 1.2.2 Phase 2: 클라우드 전환 및 AI 고도화 (미래 계획)

**목표:** 대규모 확장 대응 및 스마트 팩토리 고도화

**주요 기능 (검토 사항):**

**1. AWS 클라우드 마이그레이션**
- EC2 + RDS 기반 클라우드 배포
- S3를 통한 파일 저장 (펌웨어, 리포트)
- Auto Scaling을 통한 동적 확장
- CloudWatch 기반 모니터링

**2. AI 기반 품질 예측**
- 머신러닝 모델을 통한 불량 예측
- 공정 파라미터 최적화 추천
- 이상 탐지 (Anomaly Detection)

**3. ERP 시스템 연동**
- 생산 계획 자동 동기화
- 재고 관리 연동
- 출하 관리 연동

**4. IoT 센서 통합**
- 실시간 환경 모니터링 (온도, 습도)
- 설비 가동률 자동 수집
- 예지 보전 (Predictive Maintenance)

**전제 조건:**
- Phase 1 시스템 1년 이상 안정 운영
- 생산 규모 2배 이상 확대
- 경영진 디지털 전환 전략 승인
- 클라우드 전환 타당성 검토 완료

---

### 1.3 주요 사용자

| 사용자 유형 | 역할 | 주요 기능 |
|------------|------|----------|
| 생산 관리자 | LOT 생성, 모니터링 | React Dashboard |
| 현장 작업자 | 착공/완공 처리 | 프론트엔드 앱 (PyQt5) |
| 시스템 관리자 | 시스템 운영 관리 | 서버 관리, 백업 |


---

## 2. 제품 및 공정 현황 (AS-IS)

### 2.1 제품 소개

**제품명:** Withforce Wearable Robot

**용도:** 산업용/농업용 허리 보조 로봇

**핵심 구성품:** LMA (Linear Muscle Actuator)

**LMA 구성:**

- SMA (Shape Memory Alloy) 스프링
- 모선 케이블
- 제어 보드
- 센서 (온도, TOF)

### 2.2 주요 용어 정의

| 용어 | 설명 |
|------|------|
| **LMA** | Linear Muscle Actuator - 로봇의 핵심 구동기 |
| **SMA 스프링** | Shape Memory Alloy 스프링 - 온도로 구동 |
| **모선** | SMA 스프링을 제조하는 원재료 케이블 |
| **EOL 검사** | End Of Line 검사 - 최종 성능 검사 |
| **TOF** | Time Of Flight 센서 - 거리 측정 센서 |
| **LOT** | 동일 조건으로 생산된 제품 묶음 (100개 단위) |

### 2.3 현재 생산 공정 흐름

```mermaid
graph LR
    A[레이저 마킹] --> B[LMA 조립] --> C[센서 검사] --> D[펌웨어 업로드]
    D --> E[로봇 조립] --> F[성능검사] --> G[라벨 프린팅] --> H[포장 + 외관검사]
```

**공정 개수:** 8개

**일일 생산 목표:** 약 100대

**작업 방식:** LOT 단위 (100대), 작업대차로 이동

### 2.4 공정별 상세 설명

> **공통 사항:** 모든 공정은 작업자가 수동으로 제품을 투입하고 배출합니다. 각 공정의 소요 시간에는 투입/배출 시간이 포함되어 있습니다.

#### 2.4.1 공정 1: 레이저 마킹

**작업 내용:**
- LMA에 LOT 번호 레이저 각인

**소요 시간:** 약 60초

**품질 검사:**
- 바코드 리더기로 판독 확인
- 판독 성공 시: 합격
- 판독 실패 시: 불합격

**재작업:** 불가능 (레이저 마킹 특성상)

**작업자:** 1명

**비고:** 마킹 실패 시 해당 LMA는 불량 처리

#### 2.4.2 공정 2: LMA 조립

**작업 내용:**

- 플라스틱 부품 + SMA 스프링 조립
- 조립 순서에 따른 수작업

**소요 시간:** 약 1시간 (작업자 숙련도에 따라 편차 큼)

**품질 검사:** 작업자 육안 검사

**주요 불량 원인:**

- 조립 실수 (부품 순서 오류, 체결 불량)
- 부품 불량 (스프링 변형, 플라스틱 파손)

**재작업:** 가능 (해당 부품 교체 또는 재조립)

**작업자:** 1명

**비고:** 숙련 작업자는 40분, 신입 작업자는 1.5시간 소요

#### 2.4.3 공정 3: 센서 검사

**검사 항목:**

1. **온도 센서 검사**
   - 검사 온도: 60℃
   - 합격 기준: ±1℃ (59℃ ~ 61℃)

2. **TOF 센서 검사**
   - 검사 내용: I2C 통신 연결 확인

**소요 시간:** 약 60초

**불량률:** 거의 없음 (센서 자체 불량이 아니면 통과)

**불합격 시 처리:**

- 1차: 재검사 실시
- 2차 불합격: 센서 교체 후 재검사
- 3차 불합격: 불량 처리

**재작업:** 가능 (센서 교체)

**작업자:** 1명

#### 2.4.4 공정 4: 펌웨어 업로드

**작업 내용:**

- 대상: 제어 보드 MCU
- 펌웨어 제공: 서버 → 프론트엔드 → Local App → 제어 보드
- 버전 관리: 서버에서 펌웨어 버전 관리

**소요 시간:** 약 60초

**업로드 실패:** 종종 발생 (통신 불안정, 케이블 접촉 불량)

**실패 시 처리:**

- 자동 재시도 (최대 3회)
- 3회 실패 시: 작업자 수동 재시도
- 지속 실패 시: 제어 보드 교체

**펌웨어 버전 업데이트:** 자주 발생 (주 1회 이상)

**작업자:** 1명

**비고:** MES 시스템에서 최신 펌웨어 버전 자동 배포 필요

#### 2.4.5 공정 5: 로봇 조립

**작업 내용:**

- LMA를 로봇 본체에 조립
- 케이블 연결 및 고정

**소요 시간:** 약 1시간

**품질 검사:** 육안 외관 검사

**주요 확인 사항:**

- LMA 체결 상태
- 케이블 연결 상태 (단선, 접촉 불량)
- 외관 손상 여부

**재작업:** 가능 (조립 불량 시 재조립)

**작업자:** 1명

**비고:** 케이블 연결 불량이 주요 불량 원인

#### 2.4.6 공정 6: 성능검사

**측정 항목:**

1. **온도** (℃): LMA 구동기 가열 온도
2. **변위** (mm): LMA 구동기 이동 거리
3. **힘** (kgf): LMA 구동기가 발생하는 힘

**검사 프로토콜 예시:**

- 조건: 200mm 변위에서 LMA 구동기를 52℃로 가열
- 측정: 발생하는 힘(kgf) 측정

**측정 데이터 합격 범위:**

- 특정 온도와 스트로크(변위) 조건에서 측정된 힘(kgf)이 목표값 ±2kgf 범위 내

**검사 횟수:** 1대당 1회

**소요 시간:** 약 10분

**불량률:** 거의 없음 (이전 공정이 정상이면 대부분 통과)

**불합격 시 처리:**

- 재측정 실시
- 2회 불합격: 원인 분석 (센서, LMA 조립, 펌웨어 등)
- 해당 부품 재작업 후 재검사

**재작업:** 가능

**작업자:** 1명

#### 2.4.7 공정 7: 라벨 프린팅

**작업 내용:**

- 시리얼 번호 자동 생성
- 바코드 라벨 출력 (Zebra 프린터)
- 로봇 본체에 라벨 부착

**시리얼 번호 형식:** `WF-KR-251110D-001-0001`

**라벨 규격:**

- 크기: 60mm × 20mm
- 내용: 시리얼 번호, LOT 번호, 제품명, 생산일자

**부착 위치:** 로봇 본체 (지정 위치)

**소요 시간:**

- 라벨 출력: 약 10초
- 라벨 부착: 약 30초
- 총 소요: 약 40초

**작업자:** 1명

**비고:** 라벨 손상/분실 시 재출력 가능

#### 2.4.8 공정 8: 포장 + 외관검사

**작업 내용:**

- 로봇 외관 최종 검사
- 포장 (비닐 + 박스)

**외관 검사 항목:** (구체적 기준 미정립)

- 스크래치 확인
- 오염 확인
- 부품 누락 확인
- 라벨 부착 상태 확인

**포장 자재:**

- 비닐: 로봇 보호용
- 박스: 외부 포장 박스

**작업자:** 1명

**비고:** 외관검사 기준 명확화 필요 (MES 도입 시 체크리스트 수립 예정)

#### 2.4.9 공정 특성 요약

| 공정 | 소요 시간 | 작업자 | 불량률 | 재작업 가능 | 병목 여부 |
|------|----------|--------|--------|-----------|----------|
| 1. 레이저 마킹 | 60초 | 1명 | 낮음 | 불가 | - |
| 2. LMA 조립 | 1시간 | 1명 | 중간 | 가능 | **병목** |
| 3. 센서 검사 | 60초 | 1명 | 매우 낮음 | 가능 | - |
| 4. 펌웨어 업로드 | 60초 | 1명 | 중간 | 가능 | - |
| 5. 로봇 조립 | 1시간 | 1명 | 중간 | 가능 | **병목** |
| 6. 성능검사 | 10분 | 1명 | 매우 낮음 | 가능 | - |
| 7. 라벨 프린팅 | 60초 | 1명 | 낮음 | 가능 | - |
| 8. 포장+외관검사 | 미정 | 1명 | 낮음 | - | - |

**총 작업자:** 8명 (각 공정당 1명)

**공정 간 이동 시간:** 30초 이내 (작업대차 이동)

**총 생산 시간:** 약 2시간 10분 + 공정 간 대기 시간

**주요 병목 구간:** 공정 2 (LMA 조립), 공정 5 (로봇 조립)

### 2.5 현재 문제점 및 개선 필요사항

#### 2.5.1 현재 생산 관리 방식

**기록 방식:** 없음 (전혀 기록하지 않음)

**작업 지시:** 구두 또는 화이트보드

**품질 관리:** 개별 작업자 판단

#### 2.5.2 주요 문제점

**1. 추적성(Traceability) 부재**

- 문제 발생 시 원인 추적 불가능
- 어떤 모선 케이블을 사용했는지 알 수 없음
- 어느 공정에서 불량이 발생했는지 파악 불가

**2. 실시간 현황 파악 불가**

- 현재 생산 진행 상황을 알 수 없음
- 각 공정별 진행률 미파악
- 병목 구간 식별 불가

**3. 품질 데이터 미수집**

- 온도, 변위, 힘 측정 데이터 저장 안 됨
- 통계 분석 불가능
- 개선 근거 데이터 부족

#### 2.5.3 개선 목표

**정성적 목표:**

1. ✅ **실시간 모니터링**: 언제 어디서나 생산 현황 파악
2. ✅ **완벽한 추적성**: 시리얼 번호 → LOT → 공정 이력 → 부품 LOT 추적
3. ✅ **데이터 기반 의사결정**: 측정 데이터 수집 및 분석
4. ✅ **업무 효율성**: 자동화를 통한 작업 시간 단축

**정량적 목표:**

- LOT 생성 시간: 5분 → 30초
- 불량 원인 파악 시간: 불가능 → 5분 이내
- 생산 진행 현황 파악 시간: 1시간 → 실시간
- 완제품 수량 파악 시간: 수동 집계 → 실시간
- 공정별 재공품(WIP) 파악 시간: 파악 불가 → 실시간


### 2.6 LOT 및 시리얼 번호 체계

#### 2.6.1 LOT 번호 체계

**형식:** `[모델명]-[생산지]-[생산일자][교대조]-[순번]`

**예시:** `WF-KR-251110D-001`

**구성 요소:**

| 구분 | 길이 | 설명 | 예시 | 비고 |
|------|------|------|------|------|
| 모델명 | 2자리 | 제품 모델 코드 | WF | Withforce |
| 생산지 | 2자리 | 생산 국가 코드 | KR | 한국 (ISO 3166-1 alpha-2) |
| 생산일자 | 6자리 | 생산 날짜 | 251110 | YYMMDD 형식 (2025년 1월 10일) |
| 교대조 | 1자리 | 근무 교대조 | D | D=Day(주간), N=Night(야간) |
| 순번 | 3자리 | 일련번호 | 001 | 당일 해당 모델 생성 순서 (001~999) |

**전체 길이:** 16자리 (하이픈 구분자 포함)

**생성 규칙:**

- LOT 번호는 시스템이 자동 생성 (수동 입력 불가)
- 순번은 당일 해당 모델의 첫 번째 LOT부터 001, 002, 003... 순차 증가
- 자정(00:00) 기준으로 순번 초기화
- 교대조는 LOT 생성 시 관리자가 선택 (D 또는 N)
- 동일 날짜, 동일 교대조에서도 순번은 독립적으로 증가

**LOT 번호 예시:**

| LOT 번호 | 설명 |
|----------|------|
| `WF-KR-251110D-001` | 2025년 1월 10일 주간조 첫 번째 LOT |
| `WF-KR-251110D-002` | 2025년 1월 10일 주간조 두 번째 LOT |
| `WF-KR-251110N-001` | 2025년 1월 10일 야간조 첫 번째 LOT |
| `WF-KR-251111D-001` | 2025년 1월 11일 주간조 첫 번째 LOT (날짜 변경으로 순번 초기화) |

**확장성:**

- 향후 다른 모델 추가 시: `AG-KR-251110D-001` (AG = Agriculture 농업용)
- 향후 해외 생산지 추가 시: `WF-US-251110D-001` (US = 미국)

#### 2.6.2 시리얼 번호 체계

**형식:** `[LOT번호]-[제품순번]`

**예시:** `WF-KR-251110D-001-0001`

**구성 요소:**

| 구분 | 길이 | 설명 | 예시 | 비고 |
|------|------|------|------|------|
| LOT 번호 | 16자리 | 상위 LOT 번호 | WF-KR-251110D-001 | 2.6.1 LOT 번호 체계 참조 |
| 제품 순번 | 4자리 | LOT 내 제품 순서 | 0001 | 0001~9999 (일반적으로 0001~0100) |

**전체 길이:** 21자리 (하이픈 구분자 포함)

**생성 규칙:**

- 시리얼 번호는 **라벨 프린팅 공정(공정 7)**에서 자동 생성
- 제품 순번은 LOT당 0001부터 시작하여 순차 증가
- LOT 목표 수량이 100개이므로 일반적으로 0001~0100 범위
- 생성 순서는 라벨 프린팅 공정 착공 순서
- 생성 후 바코드 라벨로 출력되어 제품에 부착

**시리얼 번호 예시:**

| 시리얼 번호 | 설명 |
|-------------|------|
| `WF-KR-251110D-001-0001` | 해당 LOT의 첫 번째 제품 |
| `WF-KR-251110D-001-0050` | 해당 LOT의 50번째 제품 |
| `WF-KR-251110D-001-0100` | 해당 LOT의 100번째 (마지막) 제품 |

**시리얼 번호 활용:**

- 제품 개체 식별 및 추적
- 전 공정 이력 추적
- 불량 발생 시 원인 분석
- A/S 및 품질 보증
- 리콜 발생 시 대상 제품 특정

### 2.7 불량 유형 코드 체계

**목적:** 공정별 불량 유형을 표준화하여 일관된 불량 분류 및 통계 분석 가능

**사용 위치:**
- 완공 데이터 전송 시 `defect_type` 필드에 사용
- 불량 통계 및 분석 시 기준 코드로 활용
- 상세 내용은 **3.2.5 품질 및 불량 관리** 참조

**공정별 불량 유형 코드:**

| 공정 | 불량 유형 코드 | 설명 | 비고 |
|------|---------------|------|------|
| **공정 2 (LMA 조립)** | PART_DEFECT | 부품 불량 | SMA 스프링, 플라스틱 부품 등 |
| | ASSEMBLY_ERROR | 조립 불량 | 체결 불량, 순서 오류 등 |
| **공정 3 (센서 검사)** | SENSOR_TEMP_FAIL | 온도 센서 이상 | 측정값 범위 초과 |
| | SENSOR_TOF_FAIL | TOF 센서 이상 | I2C 통신 실패 |
| **공정 4 (펌웨어 업로드)** | FIRMWARE_UPLOAD_FAIL | 펌웨어 업로드 실패 | 업로드 중단, 검증 실패 |
| | FIRMWARE_COMM_ERROR | 통신 오류 | 케이블 접촉 불량, 포트 오류 |
| **공정 5 (로봇 조립)** | ASSEMBLY_ERROR | 조립 불량 | 체결 불량 |
| | APPEARANCE_DEFECT | 외관 손상 | 스크래치, 파손 등 |
| **공정 6 (성능검사)** | PERFORMANCE_FAIL | 성능 미달 | 힘 측정값 규격 미달 |
| **공정 7 (라벨 프린팅)** | LABEL_PRINT_FAIL | 라벨 출력 실패 | 프린터 오류, 용지 부족 |
| | LABEL_ATTACH_ERROR | 라벨 부착 불량 | 위치 오류, 접착 불량 |

**불량 유형 코드 사용 예시:**

완공 데이터에서 불량 발생 시:
```json
{
  "result": "FAIL",
  "process_data": {
    "defect_type": "SENSOR_TEMP_FAIL",
    "defect_description": "온도 센서 측정값 58.0℃ (허용범위: 59-61℃)"
  }
}
```

**코드 확장:**
- 향후 새로운 불량 유형 발생 시 이 테이블에 추가
- 코드 명명 규칙: `[카테고리]_[상세]_[상태]` 형식 (예: SENSOR_TEMP_FAIL)

### 2.8 API 에러 코드 체계

**목적:** MES API 호출 시 발생할 수 있는 에러를 표준화하여 일관된 에러 처리 및 디버깅 지원

**사용 위치:**

- 착공/완공 API 응답의 에러 처리
- 프론트엔드 에러 메시지 표시
- 에러 로그 및 모니터링
- 상세 내용은 **3.2 핵심 기능 요구사항**의 각 API 명세 참조

**주요 에러 코드:**

| 에러 코드 | 설명 | HTTP 상태 | 비고 |
|-----------|------|-----------|------|
| LOT_NOT_FOUND | LOT 번호가 존재하지 않음 | 404 | LOT 번호 확인 필요 |
| PREVIOUS_PROCESS_NOT_COMPLETED | 이전 공정 미완료 | 400 | 공정 순서 준수 필요 |
| DUPLICATE_START | 이미 착공된 공정 (재시도는 허용, PASS 완공 후는 불가) | 409 | 작업 상태 확인 필요 |
| INVALID_PROCESS_SEQUENCE | 잘못된 공정 순서 | 400 | 공정 흐름도 참조 |
| WORKER_NOT_FOUND | 작업자 ID 없음 | 404 | 작업자 등록 확인 |
| PROCESS_ALREADY_PASSED | 이미 PASS 완공된 공정 - 착공 불가 | 409 | 해당 LOT 작업 완료됨 |
| DUPLICATE_PASS_COMPLETE | 이미 PASS 완공된 공정 - 완공 중복 불가 | 409 | 중복 완공 방지 |
| PROCESS_NOT_STARTED | 착공하지 않은 공정 | 400 | 착공 먼저 진행 필요 |
| INVALID_PROCESS_DATA | 공정 데이터 검증 실패 | 400 | 필수 데이터 확인 |
| SERIAL_NOT_FOUND | 시리얼 번호 미존재 | 404 | 시리얼 발행 확인 필요 |
| PRINTER_NOT_FOUND | 프린터 ID가 등록되지 않음 | 404 | 프린터 설정 확인 |
| PRINTER_NOT_CONNECTED | 프린터 연결 끊김 | 503 | 프린터 전원 및 케이블 확인 |
| PRINTER_OUT_OF_PAPER | 용지 부족 | 503 | 라벨 용지 보충 |
| INVALID_LABEL_DATA | 라벨 데이터 형식 오류 | 400 | 요청 데이터 확인 |

**에러 응답 형식:**

```json
{
  "success": false,
  "error": {
    "code": "PREVIOUS_PROCESS_NOT_COMPLETED",
    "message": "이전 공정이 완료되지 않았습니다",
    "details": {
      "current_process": "센서 검사",
      "required_process": "LMA 조립",
      "required_action": "LMA 조립 공정을 먼저 완료해주세요"
    }
  }
}
```

**에러 코드 확장:**
- 향후 새로운 에러 상황 발생 시 이 테이블에 추가
- 코드 명명 규칙: `[대상]_[상태]_[동작]` 형식 (예: LOT_NOT_FOUND)
- HTTP 상태 코드는 REST API 표준 준수

---

## 3. MES 요구사항 (TO-BE)

### 3.1 전체 프로세스 개요

```mermaid
sequenceDiagram
    participant 관리자 as 생산 관리자
    participant 백엔드 as 백엔드 서버
    participant 프론트 as 프론트엔드
    participant 공정앱 as 외부 공정 앱

    Note over 관리자,백엔드: 1️⃣ LOT 생성
    관리자->>백엔드: LOT 생성 요청
    백엔드-->>관리자: LOT 번호 발급

    Note over 관리자: 2️⃣ LOT 라벨 출력
    관리자->>관리자: LOT 바코드 라벨 출력<br/>(작업대차 부착)

    Note over 프론트,백엔드: 3️⃣ 공정 착공
    프론트->>프론트: LOT 바코드 스캔
    프론트->>백엔드: 착공 등록
    백엔드-->>프론트: 착공 확인

    Note over 공정앱,프론트: 4️⃣ 공정 완공
    공정앱->>공정앱: 공정 작업 수행
    공정앱->>공정앱: JSON 완공 파일 생성
    프론트->>프론트: JSON 파일 읽기
    프론트->>백엔드: 완공 데이터 전송
    백엔드-->>프론트: 완공 확인

    Note over 프론트,백엔드: 5️⃣ 시리얼 발행
    프론트->>백엔드: Label Printing 착공
    백엔드->>백엔드: 시리얼 번호 생성
    백엔드-->>프론트: 라벨 출력

    Note over 관리자,백엔드: 6️⃣ 모니터링
    관리자->>백엔드: 생산 현황 조회
    백엔드-->>관리자: 실시간 현황 제공
```

### 3.2 핵심 기능 요구사항

> **FR (Functional Requirement):** 기능 요구사항 - 시스템이 제공해야 하는 기능을 정의

#### 3.2.1 LOT 관리

**FR-LOT-001: LOT 생성**

**생성 주체:** 생산 관리자

**생성 방법:**
- 관리자용 대시보드(React 웹 애플리케이션)에서 LOT 생성
- 입력 항목: 제품 모델, 목표 수량, 교대조
- 백엔드 서버에 LOT 생성 요청 전송

**처리 결과:**
- LOT 번호 자동 발급 (예: `WF-KR-251110D-001`, 상세 체계는 **2.6.1 LOT 번호 체계** 참조)
- 생성 시 상태: CREATED
- LOT 정보 데이터베이스 저장

**FR-LOT-002: LOT 라벨 출력**

- LOT 바코드 라벨 1장 출력
- 작업대차에 부착하여 전 공정에서 식별

**FR-LOT-003: LOT 상태 관리**

- 상태: CREATED → IN_PROGRESS → COMPLETED → CLOSED
- 각 상태 전환 이력 기록


#### 3.2.2 시리얼 번호 관리

**FR-SN-001: 시리얼 번호 생성**

- Label Printing 공정 착공 시 자동 생성
- 형식: `WF-KR-251110D-001-0001`
- LOT당 순차적으로 발급

**FR-SN-002: 시리얼 라벨 출력**

- 시리얼 번호 바코드 라벨 자동 출력
- 라벨에 포함 정보: 시리얼, LOT, 제품명, 날짜

**FR-SN-003: 라벨 재출력**

- 라벨 손상/분실 시 재출력 기능
- 재출력 이력 기록 (사유, 작업자, 시간)


#### 3.2.3 공정 관리

**FR-PROC-001: 착공 처리**

**처리 방법:**
- LOT 바코드 스캔으로 착공 등록
- 실시간 검증 (이전 공정 완료 여부)
- 즉시 피드백 제공 (성공/실패)

**착공 규칙:**
- 동일 공정에서 착공은 **여러 번 가능** (재시도 허용)
- 단, 해당 공정이 PASS 완공된 경우 착공 불가

**FR-PROC-002: 완공 처리**

**처리 방법:**
- 외부 공정 앱에서 JSON 파일로 완공 데이터 전송
- 공정별 데이터 수집 (온도, 변위, 힘, 부품 LOT 등)
- 완공 검증 및 저장

**완공 규칙:**
- **PASS 완공**: 1번만 가능 (중복 차단)
- **FAIL 완공**: 여러 번 가능 (재시도 허용)

**완공 검증 로직:**
- 프론트엔드 File Watcher가 JSON 파일 처리 전 검증
- 해당 시리얼+공정에 PASS 완공이 이미 존재하는지 백엔드에 조회
- PASS 완공 존재 시: 완공 거부, JSON 파일을 error 폴더로 이동
- FAIL 완공 또는 완공 이력 없음: 정상 처리

**FR-PROC-003: 공정 순서 제어**

- 정의된 공정 순서 준수 강제
- 이전 공정 미완료 시 착공 불가


#### 3.2.4 모니터링 및 대시보드

**FR-DASH-001: 실시간 생산 현황**

- 금일 생산 현황 (착공/완공/불량)
- LOT별 진행 상태
- 공정별 현황

**FR-DASH-002: LOT 상세 조회**

- LOT 기본 정보
- 공정별 진행 현황
- 시리얼 번호 목록

**FR-DASH-003: 추적성 조회**

- 시리얼 번호로 전체 이력 조회
- 공정별 작업 데이터
- 사용된 부품 LOT

#### 3.2.5 품질 및 불량 관리

**FR-DEFECT-001: 불량 등록 및 분류**

**불량 등록 방식:** 공정 특성에 따라 2가지 방식

**방식 1: 자동 검사 공정 (검사기 기반)**

적용 공정: 센서 검사(공정 3), 성능검사(공정 6)

처리 흐름:
1. 검사기가 자동으로 합격/불합격 판정
2. 완공 데이터에 `result: "FAIL"` 및 실패한 검사 항목 포함
3. 시스템이 자동으로 불량 등록

완공 데이터 예시:
```json
{
  "result": "FAIL",
  "process_data": {
    "temp_sensor": {
      "result": "FAIL",
      "measured_temp": 58.0,
      "target_temp": 60.0
    },
    "defect_type": "SENSOR_TEMP_FAIL",
    "defect_description": "온도 센서 측정값 범위 초과"
  }
}
```

**방식 2: 수동 작업 공정 (작업자 판단)**

적용 공정: LMA 조립(공정 2), 펌웨어 업로드(공정 4), 로봇 조립(공정 5), 라벨 프린팅(공정 7)

처리 흐름:
1. 작업자가 작업 중 불량 발견
2. 완공 시 불량 유형 선택 및 상세 내용 입력
3. 완공 데이터에 `result: "FAIL"`, `defect_type`, `defect_description` 포함
4. 시스템이 불량 등록

완공 데이터 예시:
```json
{
  "result": "FAIL",
  "process_data": {
    "defect_type": "PART_DEFECT",
    "defect_part": "SMA 스프링",
    "defect_description": "스프링 변형 발견"
  }
}
```

**불량 유형 코드:** **2.7 불량 유형 코드 체계** 참조

**처리 결과:**
- 불량 데이터베이스 저장
- 불량 상태: DEFECTED
- 실시간 대시보드에 불량 현황 반영

**FR-DEFECT-002: 불량 원인 기록 및 분석**

**기록 방법:**
- 불량 발생 시 원인 상세 기록 (자유 텍스트)
- 불량 사진 첨부 (선택)
- 작업자 의견 기록

**분석 기능:**
- 불량 유형별 통계
- 공정별 불량률
- 시리얼 번호 기반 불량 이력 추적

**FR-DEFECT-003: 불량 상태 관리**

**불량 상태:**
- DEFECTED: 불량 발생
- SCRAPPED: 폐기 처리

**상태 전환:**
- DEFECTED → SCRAPPED (폐기 결정 시)
- 모든 상태 전환 이력 기록

#### 3.2.6 사용자 및 권한 관리

**FR-USER-001: 사용자 등록 및 관리**

**등록 주체:** 시스템 관리자

**사용자 유형:**
- 작업자 (Worker): 공정 착공/완공 처리
- 생산 관리자 (Manager): LOT 생성, 생산 현황 모니터링, 불량 분석
- 시스템 관리자 (Admin): 사용자 관리, 시스템 설정, 백업/복구

**등록 정보:**
- 사용자 ID, 이름, 소속, 연락처
- 역할 (Role) 지정
- 초기 비밀번호 발급

**처리 결과:**
- 사용자 데이터베이스 저장
- 로그인 자격 증명 생성
- 역할별 권한 자동 부여

**FR-USER-002: 역할 및 권한 설정**

**권한 체계 (RBAC):**

| 기능 | 작업자 | 생산 관리자 | 시스템 관리자 |
|------|--------|-----------|-------------|
| 공정 착공/완공 | ✅ | ✅ | ✅ |
| LOT 생성/관리 | ❌ | ✅ | ✅ |
| 불량 등록 | ✅ | ✅ | ✅ |
| 대시보드 조회 | 제한적 | ✅ | ✅ |
| 추적성 조회 | ❌ | ✅ | ✅ |
| 사용자 관리 | ❌ | ❌ | ✅ |
| 시스템 설정 | ❌ | ❌ | ✅ |

**인증 방식:**
- JWT (JSON Web Token) 기반
- 세션 유효 시간: 8시간
- 모든 API 요청 시 토큰 검증


### 3.3 비기능 요구사항

#### 3.3.1 성능

- 착공 API 응답 시간: 1초 이내
- 대시보드 로딩 시간: 3초 이내
- 동시 사용자: 20명

#### 3.3.2 가용성

- 목표 시스템 가동률: 99%

#### 3.3.3 데이터 보관

- 생산 데이터: 영구 보관
- 백업: 일일 전체 백업, 6시간 증분 백업
- 백업 보관: 30일

#### 3.3.4 보안

- 사용자 인증: JWT 기반
- 역할 기반 접근 제어 (RBAC)
- 모든 변경 이력 감사 로그


### 3.4 데이터 인터페이스 요구사항

#### 3.4.1 착공 인터페이스

**개요:** 현장 작업자가 프론트엔드 앱에서 LOT 바코드를 스캔하여 공정 착공을 등록하는 인터페이스

**통신 방식:** HTTP REST API (프론트엔드 ↔ 백엔드)

**API 엔드포인트:** `POST /api/v1/process/start`

**요청 (Request) 스키마:**

```json
{
  "lot_number": "WF-KR-251110D-001",
  "line_id": "LINE-A",
  "process_id": "PROC-001",
  "process_name": "레이저 마킹",
  "equipment_id": "LASER-01",
  "worker_id": "W001",
  "start_time": "2025-01-10T09:00:00+09:00"
}
```

**필드 설명:**

| 필드 | 타입 | 필수 | 설명 |
|------|------|------|------|
| lot_number | string | Y | LOT 번호 (바코드 스캔 값) |
| line_id | string | Y | 생산 라인 ID (LINE-A, LINE-B 등) |
| process_id | string | Y | 공정 ID (PROC-001 ~ PROC-008) |
| process_name | string | Y | 공정명 (한글) |
| equipment_id | string | Y | 설비/장비 ID (LASER-01, SENSOR-CHECK-01 등) |
| worker_id | string | Y | 작업자 ID |
| start_time | string | Y | 착공 시간 (ISO 8601) |

**응답 (Response) - 성공:**

```json
{
  "status": "success",
  "message": "착공이 등록되었습니다",
  "data": {
    "lot_number": "WF-KR-251110D-001",
    "line_id": "LINE-A",
    "process_id": "PROC-001",
    "process_name": "레이저 마킹",
    "equipment_id": "LASER-01",
    "worker_id": "W001",
    "start_time": "2025-01-10T09:00:00+09:00",
    "work_order_id": "WO-20250110-001",
    "sequence_number": 1
  }
}
```

**응답 (Response) - 실패:**

```json
{
  "status": "error",
  "message": "이전 공정이 완료되지 않았습니다",
  "error_code": "PREVIOUS_PROCESS_NOT_COMPLETED",
  "data": {
    "lot_number": "WF-KR-251110D-001",
    "current_process": "센서 검사",
    "previous_process": "LMA 조립",
    "required_action": "LMA 조립 공정을 먼저 완료해주세요"
  }
}
```

**주요 에러 코드:** **2.8 API 에러 코드 체계** 참조

#### 3.4.2 완공 데이터 인터페이스

**개요:** 외부 공정 앱에서 공정 작업 완료 후 완공 데이터를 MES 백엔드로 전송하는 인터페이스

**통신 방식:** JSON 파일 기반 (File Watcher)

> **중요:** 외부 업체가 개발한 공정 앱은 소스 코드 접근이 불가능하므로 JSON 파일 기반 연동만 가능합니다.

**배경:**
- 외부 업체가 개발한 공정 앱 (레이저 마킹, 센서 검사, 성능검사 등)
- 소스 코드 접근 불가, API 연동 불가
- 파일 기반 데이터 교환 방식 채택

**데이터 전송 프로세스:**

1. 외부 공정 앱이 작업 완료 후 JSON 파일 생성
2. 지정된 디렉토리에 파일 저장: `C:\neurohub_work\pending\`
3. **프론트엔드 앱(PyQt5)의 File Watcher**가 파일 감지
4. 프론트엔드가 JSON 파일을 읽고 HTTP POST로 백엔드에 전송
5. 백엔드가 완공 데이터 파싱, 검증 및 데이터베이스 저장
6. 프론트엔드가 처리 완료 파일을 `C:\neurohub_work\completed\`로 이동
   - 전송 실패 시: `C:\neurohub_work\error\`로 이동하고 오류 로그 생성

**기본 JSON 스키마:**

```json
{
  "lot_number": "WF-KR-251110D-001",
  "line_id": "LINE-A",
  "process_id": "PROC-003",
  "process_name": "센서 검사",
  "equipment_id": "SENSOR-CHECK-01",
  "worker_id": "W001",
  "start_time": "2025-01-10T09:00:00+09:00",
  "complete_time": "2025-01-10T09:15:00+09:00",
  "process_data": {
    "공정별 데이터 (아래 참조)": "..."
  }
}
```

**필드 설명:**

| 필드 | 타입 | 필수 | 설명 |
|------|------|------|------|
| lot_number | string | Y | LOT 번호 (예: WF-KR-251110D-001, 상세는 **2.6.1 LOT 번호 체계** 참조) |
| line_id | string | Y | 생산 라인 ID (LINE-A, LINE-B 등) |
| process_id | string | Y | 공정 ID (PROC-001 ~ PROC-008) |
| process_name | string | Y | 공정명 (한글) |
| equipment_id | string | Y | 설비/장비 ID (공정별 설비 식별자) |
| worker_id | string | Y | 작업자 ID |
| start_time | string | Y | 착공 시간 (ISO 8601) |
| complete_time | string | Y | 완공 시간 (ISO 8601) |
| process_data | object | Y | 공정별 측정/검사 데이터 (아래 참조) |

**공정별 process_data 상세 스키마:**

**공정 1: 레이저 마킹**

```json
{
  "process_data": {
    "lot_number_engraved": "WF-KR-251110D-001",
    "marking_result": "SUCCESS"
  }
}
```

**공정 2: LMA 조립**

**PASS 예시:**
```json
{
  "result": "PASS",
  "process_data": {
    "sma_spring_lot": "SPRING-2025011001",
    "busbar_lot": "BUSBAR-2025011001"
  }
}
```

**FAIL 예시 (작업자 판단):**
```json
{
  "result": "FAIL",
  "process_data": {
    "sma_spring_lot": "SPRING-2025011001",
    "busbar_lot": "BUSBAR-2025011001",
    "defect_type": "PART_DEFECT",
    "defect_part": "SMA 스프링",
    "defect_description": "스프링 변형 발견"
  }
}
```

**공정 3: 센서 검사**

**PASS 예시:**
```json
{
  "result": "PASS",
  "process_data": {
    "temp_sensor": {
      "measured_temp": 60.2,
      "target_temp": 60.0,
      "tolerance": 1.0,
      "result": "PASS"
    },
    "tof_sensor": {
      "i2c_communication": true,
      "result": "PASS"
    }
  }
}
```

**FAIL 예시 (자동 검사):**
```json
{
  "result": "FAIL",
  "process_data": {
    "temp_sensor": {
      "measured_temp": 58.0,
      "target_temp": 60.0,
      "tolerance": 1.0,
      "result": "FAIL"
    },
    "tof_sensor": {
      "i2c_communication": true,
      "result": "PASS"
    },
    "defect_type": "SENSOR_TEMP_FAIL",
    "defect_description": "온도 센서 측정값 범위 초과 (58.0℃, 허용범위: 59-61℃)"
  }
}
```

**공정 4: 펌웨어 업로드**

```json
{
  "process_data": {
    "firmware_version": "v1.2.3",
    "upload_result": "SUCCESS"
  }
}
```

**공정 6: 성능검사**

```json
{
  "process_data": {
    "test_results": [
      {
        "test_point_id": "T38_P170",
        "measured_force": 12.5,
        "spec": {
          "target_force": 12.8,
          "tolerance": 1.0
        },
        "result": "PASS"
      },
      {
        "test_point_id": "T50_P180",
        "measured_force": 14.2,
        "spec": {
          "target_force": 14.5,
          "tolerance": 1.0
        },
        "result": "PASS"
      },
      {
        "test_point_id": "T52_P200",
        "measured_force": 15.8,
        "spec": {
          "target_force": 16.0,
          "tolerance": 1.0
        },
        "result": "PASS"
      }
    ],
    "overall_result": "PASS",
    "test_duration_seconds": 45,
    "tested_at": "2025-01-10T11:00:00+09:00"
  }
}
```

**공정 7: 라벨 프린팅**

```json
{
  "process_data": {
    "label_printed": true,
    "printer_id": "PRINTER-07",
    "print_time": "2025-01-10T14:30:00+09:00",
    "barcode_verified": true
  }
}
```

**공정 8: 포장 + 외관검사**

```json
{
  "process_data": {
    "inspection_result": "PASS"
  }
}
```

**참고:** 향후 포장 라벨 출력이 필요한 경우 `packaging_label_printed`, `packaging_printer_id` 등의 필드를 추가할 수 있습니다.

**파일명 규칙:**

- 형식: `{LOT_NUMBER}_{PROCESS_ID}_{TIMESTAMP}.json`
- 예시: `WF-KR-251110D-001_PROC-003_20250110090000.json`

**처리 결과:**

- 성공: 파일을 `C:\neurohub_work\completed\`로 이동
- 실패: 파일을 `C:\neurohub_work\error\`로 이동하고 오류 로그 생성

**주요 에러 코드:** **2.8 API 에러 코드 체계** 참조

**공정별 필수 데이터 및 검증 규칙:**

| 공정 | 필수 필드 | 데이터 타입 | 검증 규칙 | 비고 |
|------|----------|------------|----------|------|
| **레이저 마킹** | marking_result | string | "PASS" or "FAIL" | 마킹 품질 검사 |
| **LMA 조립** | assembly_time | number | > 0 (분) | 조립 소요 시간 |
| | 모선_lot | string | 형식: MS-YYYY-nnn | 사용된 모선 LOT 번호 |
| | visual_inspection | string | "PASS" or "FAIL" | 육안 검사 결과 |
| **센서 검사** | temp_sensor.measured_temp | number | 59.0 ~ 61.0 (℃) | 온도 센서 측정값 |
| | temp_sensor.result | string | "PASS" or "FAIL" | 온도 센서 검사 결과 |
| | tof_sensor.communication | string | "OK" or "FAIL" | TOF I2C 통신 확인 |
| | tof_sensor.result | string | "PASS" or "FAIL" | TOF 센서 검사 결과 |
| | overall_result | string | "PASS" or "FAIL" | **필수** 전체 검사 결과 |
| **펌웨어 업로드** | firmware_version | string | 형식: v1.2.3 | 업로드된 펌웨어 버전 |
| | upload_result | string | "SUCCESS" or "FAIL" | 업로드 성공 여부 |
| | board_serial | string | 길이 > 0 | MCU 보드 시리얼 |
| **로봇 조립** | assembly_time | number | > 0 (분) | 조립 소요 시간 |
| | cable_connection | string | "OK" or "FAIL" | 케이블 연결 확인 |
| | final_visual_check | string | "PASS" or "FAIL" | 최종 육안 검사 |
| **성능검사** | test_results | array | length > 0 | 측정 데이터 배열 |
| | test_results[].temperature | number | 40 ~ 70 (℃) | 측정 온도 |
| | test_results[].displacement | number | 0 ~ 250 (mm) | 측정 변위 |
| | test_results[].force | number | 0 ~ 30 (kgf) | 측정 힘 |
| | overall_result | string | "PASS" or "FAIL" | **필수** 전체 검사 결과 |
| **라벨 프린팅** | serial_number | string | 형식: WF-KR-YYMMDDX-nnn-nnnn | 생성된 시리얼 번호 |
| | label_printed | boolean | true | 라벨 출력 확인 |
| | printer_id | string | 길이 > 0 | 사용된 프린터 ID |
| **포장+외관검사** | visual_defects | array | - | 발견된 결함 목록 (빈 배열 가능) |
| | defects[].type | string | "scratch", "dirt", "dent" 등 | 결함 유형 |
| | defects[].severity | string | "minor", "major", "critical" | 결함 심각도 |
| | packaging_complete | boolean | true | 포장 완료 확인 |
| | final_result | string | "PASS" or "FAIL" | **필수** 최종 검사 결과 |

> **중요:** `overall_result` 또는 `final_result` 필드는 각 공정의 합격/불합격 판정에 필수입니다. 이 값이 "FAIL"인 경우 해당 제품은 불량으로 표시됩니다.

> **참고:** JSONB 필드 검증은 백엔드 API에서 JSON Schema 또는 Pydantic 모델을 사용하여 수행됩니다.

#### 3.4.3 라벨 출력 인터페이스

**개요:** LOT 바코드 라벨 및 시리얼 번호 바코드 라벨을 산업용 프린터로 출력하는 인터페이스

**통신 방식:** 직렬 통신 (Serial) 또는 네트워크 (TCP/IP)

**지원 프린터:**

- Zebra ZT series

**출력 대상:**

| 라벨 종류 | 출력 시점 | 포함 정보 | 관련 요구사항 |
|-----------|-----------|-----------|---------------|
| LOT 바코드 라벨 | LOT 생성 직후 | LOT 번호, 제품명, 생성일, 목표 수량 | FR-LOT-002 |
| 시리얼 번호 바코드 라벨 | Label Printing 공정 착공 시 | 시리얼 번호, LOT 번호, 제품명, 생성일 | FR-SN-002 |

**라벨 출력 요청 API:**

**API 엔드포인트:** `POST /api/v1/label/print`

**요청 (Request) - LOT 라벨:**

```json
{
  "label_type": "LOT",
  "lot_number": "WF-KR-251110D-001",
  "product_model": "Withforce",
  "target_quantity": 100,
  "created_date": "2025-01-10",
  "printer_id": "PRINTER-01"
}
```

**요청 (Request) - 시리얼 라벨:**

```json
{
  "label_type": "SERIAL",
  "serial_number": "WF-KR-251110D-001-0001",
  "lot_number": "WF-KR-251110D-001",
  "product_model": "Withforce",
  "created_date": "2025-01-10",
  "printer_id": "PRINTER-07"
}
```

**응답 (Response) - 성공:**

```json
{
  "status": "success",
  "message": "라벨이 출력되었습니다",
  "data": {
    "label_type": "SERIAL",
    "serial_number": "WF-KR-251110D-001-0001",
    "printer_id": "PRINTER-07",
    "print_time": "2025-01-10T14:30:00+09:00"
  }
}
```

**응답 (Response) - 실패:**

```json
{
  "status": "error",
  "message": "프린터 연결 실패",
  "error_code": "PRINTER_NOT_CONNECTED",
  "data": {
    "printer_id": "PRINTER-07",
    "printer_status": "offline"
  }
}
```

**주요 에러 코드:** **2.8 API 에러 코드 체계** 참조

#### 3.4.4 펌웨어 배포 인터페이스

**개요:** 공정 4 (펌웨어 업로드) 착공 시 최신 펌웨어를 백엔드에서 프론트엔드로 배포하고, 외부 로컬 앱이 제어 보드에 업로드하는 인터페이스

**배경:**
- 펌웨어는 백엔드 서버에서 중앙 관리
- 버전 불일치 방지를 위한 동기화 메커니즘 필요
- 로컬 앱이 항상 최신 펌웨어만 사용하도록 보장

**디렉토리 구조:**

```
C:\neurohub_work\firmware\
  ├── firmware_v1.2.3.bin      (펌웨어 바이너리 파일)
  └── firmware_meta.json       (메타데이터 파일)
```

**펌웨어 동기화 프로세스:**

1. **착공 시 버전 확인 (프론트엔드)**
   - 공정 4 착공 API 호출: `POST /api/v1/process/start`
   - 착공 완료 후 프론트엔드가 펌웨어 정보 조회 API 호출 (폴링)
   - **폴링 설정:**
     - API 엔드포인트: `GET /api/v1/firmware/latest`
     - 폴링 주기: 2초
     - 최대 재시도: 5회 (총 10초)
     - 타임아웃 후 작업자에게 오류 알림 및 수동 재시도 안내
   - 프론트엔드가 로컬 `firmware_meta.json`과 비교

2. **펌웨어 다운로드 (버전 불일치 시)**
   - 기존 `.bin` 파일 삭제
   - 백엔드에서 최신 펌웨어 다운로드: `GET /api/v1/firmware/download/{version}`
   - **다운로드 재시도:**
     - 최대 재시도: 3회
     - 재시도 간격: 2초, 4초, 8초 (exponential backoff)
     - 실패 시 오류 로그 기록 및 작업자 알림
   - 새 펌웨어 파일 저장: `firmware_v{version}.bin`
   - `firmware_meta.json` 업데이트

3. **로컬 앱 펌웨어 업로드**
   - 로컬 앱이 `firmware_meta.json` 감시 (File Watcher)
   - 파일 변경 감지 시 메타데이터 읽기
   - `filename`에 지정된 `.bin` 파일 존재 확인
   - MD5 해시 검증
   - 제어 보드에 펌웨어 업로드

4. **완공 보고**
   - 업로드 결과를 JSON 파일로 생성
   - 프론트엔드가 백엔드로 완공 보고: `POST /api/v1/process/complete`

**펌웨어 정보 조회 API:**

**API 엔드포인트:** `GET /api/v1/firmware/latest`

**요청 예시:**

```
GET /api/v1/firmware/latest
Authorization: Bearer {JWT_TOKEN}
```

**응답:**

```json
{
  "status": "success",
  "data": {
    "version": "v1.2.3",
    "filename": "firmware_v1.2.3.bin",
    "file_size": 65536,
    "md5_hash": "5d41402abc4b2a76b9719d911017c592",
    "download_url": "/api/v1/firmware/download/v1.2.3",
    "release_date": "2025-01-10T09:00:00+09:00"
  }
}
```

**펌웨어 다운로드 API:**

**API 엔드포인트:** `GET /api/v1/firmware/download/{version}`

**요청 예시:**

```
GET /api/v1/firmware/download/v1.2.3
Authorization: Bearer {JWT_TOKEN}
```

**응답:**
- Content-Type: `application/octet-stream`
- Content-Disposition: `attachment; filename="firmware_v1.2.3.bin"`
- Binary file stream

**firmware_meta.json 스키마:**

```json
{
  "version": "v1.2.3",
  "filename": "firmware_v1.2.3.bin",
  "file_size": 65536,
  "md5_hash": "5d41402abc4b2a76b9719d911017c592",
  "downloaded_at": "2025-01-10T10:00:15+09:00",
  "status": "READY",
  "target_mcu": "STM32F103"
}
```

**필드 설명:**

| 필드 | 타입 | 설명 |
|------|------|------|
| version | string | 펌웨어 버전 (예: v1.2.3) |
| filename | string | 펌웨어 파일명 |
| file_size | integer | 파일 크기 (bytes) |
| md5_hash | string | MD5 체크섬 (무결성 검증용) |
| downloaded_at | string | 다운로드 완료 시간 (ISO 8601) |
| status | string | 상태 (READY, UPLOADING, UPLOADED, ERROR) |
| target_mcu | string | 대상 MCU 정보 |

**로컬 앱 연동 가이드:**

로컬 앱은 다음 로직을 구현해야 합니다:

1. **파일 감시**: `firmware_meta.json` 변경 감지
2. **메타데이터 읽기**: JSON 파싱
3. **파일 검증**:
   - `filename` 필드의 파일 존재 확인
   - MD5 해시 계산 및 `md5_hash`와 비교
4. **펌웨어 업로드**:
   - 제어 보드에 시리얼/USB로 업로드
   - `status`를 "UPLOADING"으로 업데이트 (선택사항)
5. **결과 보고**: 완공 JSON 파일 생성

**완공 데이터 (공정 4: 펌웨어 업로드) 업데이트:**

```json
{
  "process_data": {
    "firmware_version": "v1.2.3",
    "upload_result": "SUCCESS"
  }
}
```

**에러 처리:**

| 상황 | 처리 방법 |
|------|-----------|
| 다운로드 실패 | 프론트엔드가 재시도 (최대 3회), 실패 시 작업자에게 알림 |
| MD5 불일치 | 로컬 앱이 펌웨어 업로드 중단, 완공 JSON에 오류 기록 |
| 업로드 실패 | 로컬 앱이 재시도 (최대 3회), 완공 JSON에 실패 기록 |
| 구버전 펌웨어 감지 | 프론트엔드가 자동으로 최신 버전 다운로드 |

#### 3.4.5 알림 조회 인터페이스

**개요:** 생산 과정에서 발생하는 이벤트(불량 발생, 목표 미달, 공정 지연 등)를 관리자 및 작업자에게 알리기 위한 알림 조회 인터페이스

**통신 방식:** REST API (폴링 기반)

**알림 유형:**

| 알림 유형 코드 | 설명 | 심각도 | 발생 조건 |
|--------------|------|--------|----------|
| DEFECT_DETECTED | 불량 발생 | HIGH | 공정 완공 시 FAIL 발생 |
| TARGET_NOT_MET | 생산 목표 미달 | MEDIUM | 일일 생산량이 목표의 80% 미만 |
| PROCESS_DELAYED | 공정 지연 | MEDIUM | 착공 후 예상 시간의 150% 초과 |
| LOT_COMPLETED | LOT 완료 | LOW | 전체 공정 완료 시 |
| FIRMWARE_UPDATE | 펌웨어 업데이트 | LOW | 새 펌웨어 버전 등록 시 |

**알림 조회 API:**

**API 엔드포인트:** `GET /api/v1/alerts`

**쿼리 파라미터:**

| 파라미터 | 타입 | 필수 | 기본값 | 설명 |
|---------|------|------|--------|------|
| status | string | N | unread | 알림 상태 (unread, read, all) |
| severity | string | N | all | 심각도 필터 (high, medium, low, all) |
| limit | number | N | 10 | 조회 개수 (최대 100) |
| offset | number | N | 0 | 페이징 오프셋 |
| start_date | string | N | - | 조회 시작일 (ISO 8601) |
| end_date | string | N | - | 조회 종료일 (ISO 8601) |

**요청 예시:**

```
GET /api/v1/alerts?status=unread&severity=high&limit=10
Authorization: Bearer {JWT_TOKEN}
```

**응답:**

```json
{
  "status": "success",
  "data": {
    "alerts": [
      {
        "alert_id": "ALT-20250110-001",
        "alert_type": "DEFECT_DETECTED",
        "severity": "high",
        "title": "불량 발생",
        "message": "LOT-WF-KR-251110D-001, 공정 3 (센서 검사)에서 불량 발생",
        "related_lot": "WF-KR-251110D-001",
        "related_process": "PROC-003",
        "created_at": "2025-01-10T09:30:00+09:00",
        "is_read": false
      },
      {
        "alert_id": "ALT-20250110-002",
        "alert_type": "PROCESS_DELAYED",
        "severity": "medium",
        "title": "공정 지연",
        "message": "LOT-WF-KR-251110D-002, 공정 5 (로봇 조립)이 예상 시간 초과",
        "related_lot": "WF-KR-251110D-002",
        "related_process": "PROC-005",
        "created_at": "2025-01-10T09:25:00+09:00",
        "is_read": false
      }
    ],
    "total": 25,
    "unread_count": 12,
    "limit": 10,
    "offset": 0
  }
}
```

**알림 읽음 처리 API:**

**API 엔드포인트:** `PUT /api/v1/alerts/{alert_id}/read`

**요청 예시:**

```
PUT /api/v1/alerts/ALT-20250110-001/read
Authorization: Bearer {JWT_TOKEN}
```

**응답:**

```json
{
  "status": "success",
  "message": "알림이 읽음 처리되었습니다",
  "data": {
    "alert_id": "ALT-20250110-001",
    "is_read": true,
    "read_at": "2025-01-10T09:35:00+09:00"
  }
}
```

**폴링 권장 주기:**
- 관리자 대시보드: 30초
- 작업자 화면: 60초
- 심각도 HIGH 알림 발생 시: 10초로 일시 단축 (5분간)

**에러 코드:** **2.8 API 에러 코드 체계** 참조


### 3.5 기능 검수 항목

이 섹션은 MES 시스템의 각 기능 요구사항이 올바르게 구현되었는지 검증하기 위한 인수 검수(Acceptance Test) 항목을 정의합니다.


#### 3.5.1 LOT 관리 검수

| 검수 ID | 검수 항목 | 검수 기준 | 검수 방법 |
|---------|----------|----------|----------|
| TC-LOT-001 | LOT 생성 기능 | 관리자 대시보드에서 LOT 생성 시 형식 준수 (`WF-KR-YYMMDD{D/N}-XXX`) | 대시보드에서 LOT 생성 후 데이터베이스 확인 |
| TC-LOT-002 | LOT 번호 자동 발급 | 당일 순번이 자동으로 증가 (001, 002, ...) | 동일 날짜에 여러 LOT 생성 후 순번 확인 |
| TC-LOT-003 | LOT 라벨 출력 | LOT 생성 시 바코드 라벨 자동 출력 성공 | Zebra 프린터로 라벨 출력 확인 |
| TC-LOT-004 | 중복 LOT 방지 | 동일한 LOT 번호를 재생성 시도 시 오류 반환 | 동일 LOT 번호로 생성 시도 후 오류 메시지 확인 |
| TC-LOT-005 | LOT 상태 관리 | LOT 생성 시 CREATED 상태, 모든 공정 완료 시 COMPLETED | 각 상태 변경 시점에 DB 확인 |
| TC-LOT-006 | LOT 조회 기능 | 대시보드에서 LOT 번호로 상세 정보 조회 가능 | LOT 검색 후 기본 정보 및 공정 현황 표시 확인 |


#### 3.5.2 시리얼 번호 관리 검수

| 검수 ID | 검수 항목 | 검수 기준 | 검수 방법 |
|---------|----------|----------|----------|
| TC-SN-001 | 시리얼 번호 생성 | 라벨 프린팅 공정 착공 시 자동 생성, 형식 준수 (`WF-KR-YYMMDD{D/N}-XXX-YYYY`) | 라벨 프린팅 착공 후 DB에서 시리얼 번호 확인 |
| TC-SN-002 | 시리얼 순차 발급 | LOT당 0001부터 순차 증가 | 동일 LOT 내 여러 제품의 시리얼 번호 확인 |
| TC-SN-003 | 시리얼 라벨 출력 | 시리얼 번호 생성 시 바코드 라벨 자동 출력 | Zebra 프린터로 라벨 출력 및 내용 확인 |
| TC-SN-004 | 라벨 재출력 기능 | 라벨 손상/분실 시 재출력 가능, 이력 기록됨 | 재출력 요청 후 이력 테이블 확인 (사유, 작업자, 시간) |
| TC-SN-005 | 시리얼 중복 방지 | 동일 시리얼 번호 재발급 불가 | 동일 시리얼 생성 시도 시 오류 확인 |


#### 3.5.3 공정 관리 검수

| 검수 ID | 검수 항목 | 검수 기준 | 검수 방법 |
|---------|----------|----------|----------|
| TC-PROC-001 | 착공 등록 | LOT 바코드 스캔 시 착공 API 정상 호출 및 성공 응답 | 프론트엔드에서 바코드 스캔 후 HTTP 200 응답 확인 |
| TC-PROC-002 | 착공 검증 | 이전 공정 미완료 시 착공 불가, 적절한 오류 메시지 반환 | 공정 순서 위반 시도 후 에러 코드 확인 (`PREVIOUS_PROCESS_NOT_COMPLETED`) |
| TC-PROC-003 | 완공 등록 | JSON 파일 생성 시 백엔드가 자동 감지 및 처리 | File Watcher가 JSON 파일 감지, DB 저장 확인 |
| TC-PROC-004 | 완공 데이터 검증 | 공정별 필수 데이터 누락 시 오류 처리 | 필수 필드 누락 JSON 전송 후 오류 로그 확인 |
| TC-PROC-005 | 완공 파일 이동 | 처리 성공 시 `completed/`, 실패 시 `error/`로 이동 | 각 경우의 파일 이동 경로 확인 |
| TC-PROC-006 | 공정 순서 제어 | 정의된 순서대로만 진행 가능 | 순서 위반 시도 시 착공 차단 확인 |
| TC-PROC-007 | 작업자 기록 | 각 공정 착공/완공 시 작업자 ID 기록 | DB에서 작업자 정보 확인 |
| TC-PROC-008 | 시간 기록 | 착공/완공 시간 정확히 기록 | DB 타임스탬프와 실제 시간 비교 (오차 1초 이내) |


#### 3.5.4 실시간 모니터링 검수

| 검수 ID | 검수 항목 | 검수 기준 | 검수 방법 |
|---------|----------|----------|----------|
| TC-DASH-001 | 금일 생산 현황 | 착공/완공/불량 수량 정확히 표시 | DB 집계값과 대시보드 표시값 비교 |
| TC-DASH-002 | LOT별 진행 상태 | 각 LOT의 현재 공정 및 진행률 표시 | 대시보드 표시값과 실제 DB 데이터 비교 |
| TC-DASH-003 | 대시보드 폴링 업데이트 | 10초 주기 폴링, 데이터 변경 시 10초 이내 반영 | 착공/완공 후 최대 10초 이내 대시보드 갱신 확인 |
| TC-DASH-004 | 대시보드 로딩 시간 | 초기 로드 시간 3초 이내 | 브라우저 개발자 도구로 로딩 시간 측정 |
| TC-DASH-005 | 알림 폴링 | 30초 주기로 알림 조회 API 호출 | 네트워크 탭에서 `/api/v1/alerts` 호출 주기 확인 |


#### 3.5.5 추적성 검수

| 검수 ID | 검수 항목 | 검수 기준 | 검수 방법 |
|---------|----------|----------|----------|
| TC-TRACE-001 | LOT 이력 조회 | LOT 번호로 전체 공정 이력 조회 가능 | 대시보드에서 LOT 검색 후 8개 공정 이력 확인 |
| TC-TRACE-002 | 시리얼 이력 조회 | 시리얼 번호로 개별 제품의 상세 이력 조회 | 시리얼 검색 후 공정별 데이터 확인 |
| TC-TRACE-003 | 부품 LOT 추적 | 사용된 부품 LOT 정보 기록 및 조회 가능 | 조립 공정 데이터에서 부품 LOT 확인 (모선, 링크 등) |
| TC-TRACE-004 | 불량 추적 | 불량 발생 시 해당 공정 및 원인 추적 가능 | 불량 데이터 입력 후 이력 조회로 추적 |
| TC-TRACE-005 | 작업자 추적 | 각 공정 작업자 정보 조회 가능 | 이력 조회 시 작업자 ID 표시 확인 |
| TC-TRACE-006 | 데이터 무결성 | 모든 공정 데이터 누락 없이 저장 | 샘플 LOT의 전체 공정 데이터 완전성 확인 |

---

## 4. 시스템 아키텍처

### 4.0 시스템 규모 및 성능 요구사항

**설계 목표 규모:**

| 항목 | 목표 값 | 비고 |
|------|---------|------|
| **동시 접속자** | 100명 | 작업자 + 관리자 + 외부 시스템 |
| **작업 PC** | 7-20대 | 공정별 확장 가능 |
| **관리자 대시보드** | 10-30명 | 생산 관리자, 품질 관리자, 경영진 |
| **일일 트랜잭션** | ~50,000건 | 착공/완공 각 800건 + 조회 48,000건 |
| **피크 TPS** | ~20 TPS | 오전 9시, 오후 1시 작업 시작 시간대 |
| **API 응답 시간** | < 200ms (P95) | 착공/완공 API 기준 |
| **대시보드 로딩** | < 2초 | 초기 로드 시간 |
| **대시보드 폴링 주기** | 10초 | 생산 현황 갱신 (Phase 1 MVP) |
| **알림 폴링 주기** | 30초 | 불량/알림 조회 (Phase 1 MVP) |
| **데이터 보관** | 3년 | 법적 요구사항 준수 |
| **시스템 가동률** | 99.5% | 월 최대 다운타임 3.6시간 |

**성능 산출 근거:**

```
일일 생산량: 100대
공정 수: 8개
작업일: 주 5일

- 착공/완공 트랜잭션: 100대 × 8공정 × 2(착공+완공) = 1,600건/일
- 대시보드 조회: 30명 × 평균 50회/일 = 1,500건/일
- 모니터링 API: 10명 × 10초마다 × 8시간 = 28,800건/일
- 기타 조회: 약 20,000건/일

총합: 약 50,000건/일
피크 시간(2시간): 10,000건 / 7,200초 ≈ 1.4 TPS (여유율 고려 20 TPS 설계)
```

**확장성 요구사항:**

- 향후 2년 내 동시 접속자 **200명**까지 확장 가능해야 함
- 일일 생산량 **500대** 규모까지 대응 가능해야 함
- 수평 확장(Scale-out) 가능한 아키텍처 설계


### 4.1 배포 옵션 비교

본 시스템은 **세 가지 배포 방식** 중 선택 가능하도록 설계되었습니다. 각 옵션은 12-Factor App 원칙에 따라 환경 변수 기반으로 구성되어, 코드 변경 없이 배포 환경을 전환할 수 있습니다.

#### 4.1.1 배포 옵션 개요

| 구분 | Option A: 온프레미스 | Option B-1: Railway | Option B-2: AWS |
|------|---------------------|---------------------|-----------------|
| **배포 방식** | 자체 서버 구축 | Cloud PaaS | Cloud IaaS |
| **인프라** | 물리 서버 구매/설치 | Railway 플랫폼 | EC2, RDS, ElastiCache |
| **데이터베이스** | 자체 PostgreSQL | Railway PostgreSQL | AWS RDS PostgreSQL |
| **캐시** | 자체 Redis | Railway Redis | AWS ElastiCache |
| **파일 저장소** | 로컬 스토리지 | Railway Volume | AWS S3 |
| **배포 시간** | 4-6주 | 1주 | 2-3주 |
| **확장 방식** | 서버 추가 구매 | 자동 스케일링 | 수동/자동 스케일링 |

#### 4.1.2 상세 비교

##### 초기 투자 비용

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **서버/인프라** | 4,985만원 | 0원 | 0원 |
| **개발비** | 1,805만원 | 1,805만원 | 1,805만원 |
| **합계** | **6,790만원** | **1,805만원** | **1,805만원** |

**온프레미스 서버 구성 (4,985만원):**
- 백엔드 서버: Dell PowerEdge R250 (2대) - 1,800만원
- DB 서버: Dell PowerEdge R350 (1대) - 1,200만원
- 네트워크 장비: 스위치, 라우터, UPS - 800만원
- 설치/구축비: 케이블링, 랙 구성 - 500만원
- 기타: 라이선스, 보안 솔루션 - 685만원

##### 월 운영 비용

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **인프라 비용** | 0원 | 26만원 | 220-350만원 |
| **전기/네트워크** | 20만원 | 0원 | 0원 |
| **유지보수** | 93만원 | 0원 | 0원 |
| **합계** | **113만원** | **26만원** | **220-350만원** |

**Railway 상세 (월 26만원):**
- Hobby Plan: $20/월 (약 26만원)
- PostgreSQL, Redis, 백엔드 포함
- 500MB RAM, 1GB Storage 기본 제공
- 트래픽: 무제한

**AWS 상세 (월 220-350만원):**
- EC2 t3.medium (2대): $60/월
- RDS PostgreSQL db.t3.medium: $80/월
- ElastiCache Redis t3.micro: $15/월
- S3 Storage: $10/월
- Data Transfer: $50-180/월 (변동)

**온프레미스 유지보수 (월 93만원):**
- 전기료: 20만원/월
- 시스템 관리: 50만원/월 (파트타임 관리자)
- 백업/모니터링 툴: 23만원/월

##### 3년 총 소유 비용 (TCO)

| 구분 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **초기 투자** | 6,790만원 | 1,805만원 | 1,805만원 |
| **36개월 운영** | 4,068만원 | 936만원 | 7,920-12,600만원 |
| **3년 총 비용** | **10,858만원** | **2,741만원** | **9,725-14,405만원** |

##### 개발 일정

| 단계 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **인프라 구축** | 2-3주 | 0일 | 3-5일 |
| **네트워크 설정** | 1주 | 0일 | 2-3일 |
| **백엔드 개발** | 8주 | 8주 | 8주 |
| **배포/테스트** | 1주 | 2일 | 3-5일 |
| **합계** | **12-13주** | **8주** | **9-10주** |

##### 장단점 비교

**Option A: 온프레미스**

**장점:**
- ✅ 데이터 완전 통제 (보안 중시 기업에 적합)
- ✅ 장기 운영 시 월 비용 낮음 (월 113만원)
- ✅ 인터넷 의존성 낮음 (로컬 네트워크만 필요)
- ✅ 커스터마이징 자유도 높음

**단점:**
- ❌ 초기 투자 비용 높음 (6,790만원)
- ❌ 구축 기간 길음 (12-13주)
- ❌ 시스템 관리자 필요
- ❌ 하드웨어 장애 시 복구 부담
- ❌ 확장 시 서버 추가 구매 필요

**추천 대상:**
- 데이터 보안이 최우선인 기업
- 3년 이상 장기 운영 계획
- IT 인프라 관리 인력 보유
- 초기 투자 여력 있음

---

**Option B-1: Railway (Cloud PaaS)**

**장점:**
- ✅ 초기 투자 최소화 (1,805만원)
- ✅ 가장 빠른 배포 (8주)
- ✅ 월 비용 최저 (26만원)
- ✅ 인프라 관리 불필요
- ✅ 자동 백업/모니터링 제공
- ✅ 개발자 친화적 (GitHub 연동 자동 배포)

**단점:**
- ❌ 플랫폼 종속성 (Railway 의존)
- ❌ 커스터마이징 제약
- ❌ 대규모 트래픽 시 비용 급증 가능
- ❌ 인터넷 연결 필수

**추천 대상:**
- 빠른 시작이 중요한 스타트업
- IT 인프라 관리 인력 부족
- 초기 투자 최소화 필요
- 클라우드 기반 확장 계획

---

**Option B-2: AWS (Cloud IaaS)**

**장점:**
- ✅ 초기 투자 낮음 (1,805만원)
- ✅ 엔터프라이즈급 신뢰성
- ✅ 세밀한 인프라 제어 가능
- ✅ 다양한 AWS 서비스 통합 가능
- ✅ 대규모 확장성 (글로벌 인프라)

**단점:**
- ❌ 월 비용 높음 (220-350만원)
- ❌ AWS 전문 지식 필요
- ❌ 설정/관리 복잡도 높음
- ❌ 트래픽 비용 예측 어려움

**추천 대상:**
- 엔터프라이즈급 안정성 필요
- AWS 기존 인프라 보유
- 글로벌 확장 계획
- 클라우드 전문 인력 보유

#### 4.1.3 의사결정 가이드

**1단계: 초기 투자 검토**

```
Q1. 초기 투자 6,790만원 가능한가?
├─ YES → 온프레미스 검토
└─ NO  → Railway 또는 AWS 검토
```

**2단계: 운영 기간 검토**

```
Q2. 3년 이상 장기 운영 계획인가?
├─ YES → 온프레미스 (3년 TCO: 10,858만원)
└─ NO  → Railway (3년 TCO: 2,741만원)
```

**3단계: 데이터 보안 요구사항**

```
Q3. 데이터를 반드시 자체 서버에 보관해야 하는가?
├─ YES → 온프레미스
└─ NO  → Railway 또는 AWS
```

**4단계: IT 인프라 관리 능력**

```
Q4. IT 인프라 관리 인력이 있는가?
├─ YES → 온프레미스 또는 AWS
└─ NO  → Railway (관리 불필요)
```

**5단계: 확장성 요구사항**

```
Q5. 향후 급격한 확장 가능성이 있는가?
├─ YES → Railway (자동 스케일링) 또는 AWS (대규모 확장)
└─ NO  → 온프레미스 (안정적 소규모 운영)
```

#### 4.1.4 마이그레이션 전략

**온프레미스 → 클라우드 전환:**

본 시스템은 12-Factor App 원칙에 따라 설계되어, 환경 변수만 변경하면 배포 환경을 전환할 수 있습니다.

**1단계: 환경 변수 변경**

```bash
# 온프레미스
DATABASE_URL=postgresql://user:pass@192.168.1.100:5432/mes_db
REDIS_URL=redis://192.168.1.101:6379
FILE_STORAGE=local

# Railway로 전환
DATABASE_URL=postgresql://user:pass@railway.app:5432/mes_db
REDIS_URL=redis://railway.app:6379
FILE_STORAGE=railway_volume

# AWS로 전환
DATABASE_URL=postgresql://user:pass@mes-db.rds.amazonaws.com:5432/mes_db
REDIS_URL=redis://mes-cache.elasticache.amazonaws.com:6379
FILE_STORAGE=s3://mes-bucket
```

**2단계: 데이터 마이그레이션**

```bash
# PostgreSQL 데이터 덤프
pg_dump -h 192.168.1.100 -U mes_user mes_db > mes_backup.sql

# Railway/AWS로 복원
psql $DATABASE_URL < mes_backup.sql
```

**3단계: 파일 마이그레이션**

```bash
# 로컬 파일 → S3 (AWS의 경우)
aws s3 sync /var/mes/files/ s3://mes-bucket/

# 로컬 파일 → Railway Volume
railway volume upload /var/mes/files/
```

**마이그레이션 다운타임:** 2-4시간 (데이터 크기에 따라)

#### 4.1.5 하이브리드 옵션

**시작: Railway → 성장: AWS → 성숙: 온프레미스**

일부 기업은 단계별로 배포 전략을 변경하기도 합니다:

1. **Phase 1 (0-1년):** Railway로 빠르게 시작
   - 초기 투자 최소화
   - 빠른 시장 진입
   - 월 26만원 운영

2. **Phase 2 (1-2년):** AWS로 전환
   - 안정성 강화 필요 시
   - 더 많은 제어권 필요 시
   - 월 220-350만원 운영

3. **Phase 3 (3년+):** 온프레미스 전환
   - 3년 이상 장기 운영 확정 시
   - TCO 최적화 (3년차부터 온프레미스가 유리)
   - 초기 6,790만원 투자 후 월 113만원 운영

---

### 4.2 시스템 구성도

본 섹션에서는 배포 옵션별 시스템 아키텍처 구성도를 제공합니다.

#### 4.2.1 Option A: 온프레미스 구성도

```mermaid
graph TB
    subgraph Factory["생산 현장 (공장 내부)"]
        PC1[작업 PC 1-7<br/>PyQt5 App]
        PC2[바코드 스캐너]
        PC3[라벨 프린터<br/>Zebra ZT]
    end

    subgraph OnPremServer["온프레미스 서버실"]
        subgraph BackendServers["백엔드 서버 (2대)"]
            Backend1[FastAPI Server 1]
            Backend2[FastAPI Server 2]
        end
        subgraph DBServer["DB 서버 (1대)"]
            DB[(PostgreSQL 15+)]
            Redis[(Redis 7.0+)]
        end
        Nginx[Nginx<br/>Load Balancer]
    end

    subgraph Office["관리자 (사무실)"]
        Dashboard[React Dashboard<br/>웹 브라우저]
    end

    PC1 -->|WiFi| Nginx
    PC2 --> PC1
    PC3 --> PC1
    Dashboard -->|WiFi/VPN| Nginx
    Nginx --> Backend1
    Nginx --> Backend2
    Backend1 --> DB
    Backend1 --> Redis
    Backend2 --> DB
    Backend2 --> Redis
```

#### 4.2.2 Option B-1: Railway 구성도

```mermaid
graph TB
    subgraph Factory["생산 현장"]
        PC1[작업 PC 1-7<br/>PyQt5 App]
        PC2[바코드 스캐너]
        PC3[라벨 프린터<br/>Zebra ZT]
    end

    subgraph RailwayCloud["Railway Cloud Platform"]
        Backend[FastAPI Service<br/>Auto-scaled]
        DB[(Railway PostgreSQL)]
        Redis[(Railway Redis)]
        Volume[Railway Volume<br/>File Storage]
    end

    subgraph Office["관리자"]
        Dashboard[React Dashboard<br/>웹 브라우저]
    end

    PC1 -->|HTTPS| Backend
    PC2 --> PC1
    PC3 --> PC1
    Dashboard -->|HTTPS| Backend
    Backend --> DB
    Backend --> Redis
    Backend --> Volume
```

#### 4.2.3 Option B-2: AWS 구성도

```mermaid
graph TB
    subgraph Factory["생산 현장"]
        PC1[작업 PC 1-7<br/>PyQt5 App]
        PC2[바코드 스캐너]
        PC3[라벨 프린터<br/>Zebra ZT]
    end

    subgraph AWS["AWS Cloud"]
        subgraph VPC["VPC (Virtual Private Cloud)"]
            ALB[Application Load Balancer]
            subgraph EC2["EC2 Instances"]
                Backend1[FastAPI Server 1<br/>t3.medium]
                Backend2[FastAPI Server 2<br/>t3.medium]
            end
            RDS[(RDS PostgreSQL<br/>db.t3.medium)]
            ElastiCache[(ElastiCache Redis<br/>t3.micro)]
            S3[S3 Bucket<br/>File Storage]
        end
    end

    subgraph Office["관리자"]
        Dashboard[React Dashboard<br/>웹 브라우저]
    end

    PC1 -->|HTTPS| ALB
    PC2 --> PC1
    PC3 --> PC1
    Dashboard -->|HTTPS| ALB
    ALB --> Backend1
    ALB --> Backend2
    Backend1 --> RDS
    Backend1 --> ElastiCache
    Backend1 --> S3
    Backend2 --> RDS
    Backend2 --> ElastiCache
    Backend2 --> S3
```

---

### 4.3 기술 스택

본 시스템의 기술 스택은 **배포 옵션과 무관하게 동일**합니다. 12-Factor App 원칙에 따라 환경 변수만 변경하면 온프레미스, Railway, AWS 어디서나 동일하게 동작합니다.

**설계 기준:** 동시 접속자 100명 규모

#### 4.3.1 Backend (공통)

**언어 및 프레임워크:**
- 언어: Python 3.11+
- 프레임워크: FastAPI
- ASGI 서버: Uvicorn (multi-worker)
- 프로세스 관리: Gunicorn + Uvicorn workers
- ORM: SQLAlchemy 2.0 (async)
- 마이그레이션: Alembic

**성능 최적화:**
- Worker 프로세스: CPU 코어 수 × 2 (예: 4코어 → 8 workers)
- Connection Pool:
  - 최소 연결: 10
  - 최대 연결: 50
  - Overflow: 20
- 비동기 I/O: asyncio, httpx

#### 4.3.2 Database (배포 옵션별)

**공통 사양:**
- DBMS: PostgreSQL 15+
- Connection Pool: asyncpg
  - pool_size: 20-50 (동시 접속자에 따라 조정)
  - max_overflow: 10
- 인덱싱 전략:
  - lot_number, process_id, worker_id에 인덱스
  - 복합 인덱스: (lot_number, process_id, created_at)
  - 파티셔닝: 3개월 단위 날짜 파티셔닝 (선택사항)

**배포 옵션별 구성:**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **PostgreSQL** | 자체 설치 (서버) | Railway PostgreSQL | RDS PostgreSQL |
| **버전** | 15+ | Railway 관리 | 15+ |
| **스토리지** | 로컬 디스크 500GB | Railway Disk | RDS gp3 500GB |
| **백업** | pg_dump (cron) | 자동 (Railway) | 자동 (RDS snapshot) |
| **접속 URL** | `postgresql://192.168.1.100:5432/mes_db` | `$DATABASE_URL` (Railway 자동) | `postgresql://mes-db.rds.amazonaws.com:5432/mes_db` |

**Caching:**
- L1 Cache: 애플리케이션 인메모리 (LRU, max 1000 items)
- L2 Cache: Redis 7.0+
  - 용도: 세션, 임시 데이터, API 캐시
  - TTL: 5분~1시간 (데이터 특성별)
  - 메모리: 4GB 권장 (온프레미스), Railway 자동, ElastiCache t3.micro (AWS)
  - Persistence: AOF (Append Only File)

**Redis 배포 옵션별:**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **Redis** | 자체 설치 (서버) | Railway Redis | ElastiCache Redis |
| **메모리** | 4GB | Railway 자동 | t3.micro (512MB) |
| **접속 URL** | `redis://192.168.1.101:6379` | `$REDIS_URL` (Railway 자동) | `redis://mes-cache.elasticache.amazonaws.com:6379` |

#### 4.3.3 Load Balancing & Reverse Proxy (배포 옵션별)

**공통 기능:**
- HTTP/2 지원
- SSL/TLS 종단 처리
- Static file 서빙 (React build)
- Gzip 압축
- Rate Limiting: 100 req/min per IP
- Health Check: /health 엔드포인트 확인
- Timeout: 30초

**배포 옵션별 구성:**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **로드 밸런서** | Nginx 1.24+ | Railway 내장 | AWS ALB |
| **알고리즘** | Least Connections | 자동 | Round Robin/Least Outstanding |
| **SSL 인증서** | Let's Encrypt | Railway 자동 (*.up.railway.app) | AWS ACM |
| **Health Check 주기** | 10초 | Railway 자동 | 30초 |
| **설정 방법** | nginx.conf 수동 편집 | railway.json | AWS Console/Terraform |

#### 4.3.4 Frontend - 작업 PC (공통)

**프레임워크:**
- PyQt5 (Python 3.11+)
- 통신: httpx (async HTTP client)
- 파일 감시: watchdog
- 프린터 통신: pyserial
- 바코드 스캐너: USB HID

**로컬 저장소:**
- SQLite (오프라인 작업 지원)
- 디렉토리: C:\neurohub_work\

**환경 변수 설정 (배포 옵션별):**

```python
# 온프레미스
API_BASE_URL=http://192.168.1.100:8000

# Railway
API_BASE_URL=https://mes-backend.up.railway.app

# AWS
API_BASE_URL=https://mes-api.yourdomain.com
```

#### 4.3.5 Dashboard - 관리자 (공통)

**접속 방식 (배포 옵션별):**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **망내 접속** | `http://192.168.1.100:3000` | `https://mes-dashboard.up.railway.app` | `https://dashboard.yourdomain.com` |
| **망외 접속** | VPN 필요 | 인터넷 접속 가능 | 인터넷 접속 가능 |
| **SSL/TLS** | Let's Encrypt 설정 | Railway 자동 제공 | AWS ACM 설정 |

**지원 브라우저:** Chrome, Edge, Firefox (최신 버전)

**사용자:**
- 생산 관리자: 생산 현황, LOT 생성/관리
- 품질 관리자: 불량 통계, 품질 분석
- 경영진: 주요 KPI 대시보드

**Frontend:**
- 프레임워크: React 18+
- 상태 관리: Zustand 또는 Redux Toolkit
- UI 라이브러리: Material-UI (MUI) 또는 Ant Design
- 차트: Chart.js 또는 Recharts
- 테이블: TanStack Table (React Table)
- HTTP Client: Axios
- 빌드 도구: Vite

**데이터 갱신 방식:**
- REST API 폴링 기반
- 대시보드 조회: `GET /api/v1/dashboard/summary` (10초 주기)
- 알림 조회: `GET /api/v1/alerts` (30초 주기)
- 자동 재시도: 실패 시 exponential backoff (2초, 4초, 8초)

#### 4.3.6 Infrastructure (배포 옵션별)

**운영 체제 및 컨테이너:**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **OS** | Ubuntu 22.04 LTS | Railway 관리 (Linux) | Ubuntu 22.04 LTS (EC2) |
| **컨테이너** | Docker + Docker Compose | Railway 내장 (Dockerfile 지원) | Docker + ECS (선택) |
| **프로세스 관리** | systemd 또는 Docker | Railway 자동 | systemd 또는 ECS |

**백업 전략:**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **DB 백업** | pg_dump (cron, 새벽 2시) | Railway 자동 (매일) | RDS 자동 스냅샷 (매일) |
| **증분 백업** | WAL archiving (선택) | Railway 관리 | RDS PITR (Point-in-Time Recovery) |
| **보관 주기** | 30일 (수동 관리) | Railway 자동 | 35일 (설정 가능) |
| **파일 백업** | NAS 또는 외부 스토리지 | Railway Volume 스냅샷 | S3 Versioning + Lifecycle |
| **복원 시간** | 수동 복원 (1-2시간) | Railway CLI (10분) | RDS 복원 (10-30분) |

**파일 저장소:**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **완공 JSON** | 로컬 디스크 (90일 보관) | Railway Volume | S3 (Lifecycle: 90일) |
| **펌웨어** | 로컬 디스크 (영구) | Railway Volume | S3 (영구, Glacier 아카이브) |
| **위치** | /var/mes/files/ | /app/files/ (Volume) | s3://mes-bucket/ |

#### 4.3.7 모니터링 & 로깅 (배포 옵션별)

**로깅 (공통):**
- 구조화 로깅: structlog (JSON 포맷)
- 로그 레벨: INFO (production), DEBUG (development)

**로그 저장 (배포 옵션별):**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **로그 파일** | /var/log/neurohub/ (30일 rotation) | Railway Logs (7일) | CloudWatch Logs (30일) |
| **중앙 집중** | Loki (선택사항) | Railway 대시보드 | CloudWatch Logs Insights |
| **검색** | grep 또는 Loki Query | Railway CLI | CloudWatch Query |
| **보관 비용** | 디스크 비용 포함 | 무료 (7일) | $0.50/GB/월 |

**모니터링 (배포 옵션별):**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **메트릭 수집** | Prometheus (자체 구축) | Railway Metrics (내장) | CloudWatch |
| **시각화** | Grafana (자체 구축) | Railway Dashboard | CloudWatch Dashboard |
| **알림** | Alertmanager → Slack/Email | Railway Alerts | CloudWatch Alarms → SNS |
| **수집 간격** | 15초 | Railway 자동 | 1분 (기본), 5초 (상세) |
| **보관 주기** | 90일 | Railway 자동 | 15개월 (CloudWatch) |

**공통 알림 기준:**
- CPU > 80% (5분 이상)
- 메모리 > 85%
- API 응답 시간 > 500ms (P95)
- 에러율 > 1%

**APM (선택사항):**
- OpenTelemetry (분산 추적)
- Jaeger (온프레미스), Railway APM (Railway), AWS X-Ray (AWS)

#### 4.3.8 보안 (배포 옵션별)

**인증 & 인가 (공통):**
- JWT (Access Token + Refresh Token)
  - Access Token TTL: 15분
  - Refresh Token TTL: 7일
- RBAC (Role-Based Access Control)
  - 역할: 관리자, 생산관리자, 작업자, 뷰어

**네트워크 보안 (배포 옵션별):**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **HTTPS/SSL** | Nginx + Let's Encrypt | Railway 자동 (*.up.railway.app) | ALB + ACM |
| **방화벽** | UFW (Ubuntu Firewall) | Railway 내장 | Security Groups |
| **허용 포트** | 22, 80, 443 | Railway 자동 관리 | 80, 443 (ALB) |
| **내부망 포트** | PostgreSQL (5432), Redis (6379) | Railway Private Network | VPC 내부 (보안 그룹) |
| **Rate Limiting** | slowapi (FastAPI middleware) | Railway 내장 + slowapi | ALB + slowapi |
| **DDoS 방어** | Fail2ban (선택사항) | Railway 자동 | AWS Shield Standard |

**데이터 보안 (공통):**
- 암호화: bcrypt (비밀번호 해싱)
- 감사 로그: 모든 CUD 작업 기록
- SQL Injection 방지: ORM (SQLAlchemy parameterized queries)

#### 4.3.9 테스트 (공통)

**Backend:**
- 단위 테스트: pytest
- API 테스트: pytest + httpx
- 부하 테스트: Locust (목표: 20 TPS, 100 동시 사용자)

**Frontend:**
- React: Jest + React Testing Library
- E2E: Playwright (선택사항)

**CI/CD (배포 옵션별):**

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **CI** | GitHub Actions | Railway 내장 CI | GitHub Actions + CodeBuild |
| **CD** | 수동 배포 (SSH) | GitHub Push → 자동 배포 | CodeDeploy 또는 수동 |
| **테스트 자동화** | GitHub Actions | Railway Build 시 pytest 실행 | GitHub Actions |

#### 4.3.10 개발 도구 (공통)

**버전 관리:**
- Git + GitHub/GitLab
- 브랜치 전략: Git Flow

**API 문서:**
- FastAPI 자동 생성 (Swagger UI, ReDoc)
- 엔드포인트: /docs, /redoc

**환경 변수 관리:**
- 온프레미스: .env 파일 (python-dotenv)
- Railway: Railway Dashboard 또는 CLI
- AWS: Systems Manager Parameter Store 또는 .env

---

#### 4.3.11 기술 스택 요약표

| 계층 | 기술 | 목적 | 우선순위 |
|------|------|------|----------|
| **Load Balancer** | Nginx | 부하 분산, SSL 종단 | High |
| **Backend** | FastAPI + Uvicorn | REST API 서버 | High |
| **Database** | PostgreSQL 15+ | 관계형 데이터 저장 | High |
| **Cache** | Redis | 세션, API 캐시 | High |
| **ORM** | SQLAlchemy 2.0 | 데이터베이스 추상화 | High |
| **Frontend (작업 PC)** | PyQt5 | 데스크톱 앱 | High |
| **Dashboard** | React 18 | 관리자 웹 | High |
| **모니터링** | Prometheus + Grafana | 시스템 모니터링 | High |
| **로깅** | structlog | 구조화 로그 | Medium |
| **백업** | pg_dump + Cron | 데이터 백업 | High |
| **컨테이너** | Docker | 배포 환경 관리 | Medium |
| **APM** | OpenTelemetry | 분산 추적 (선택) | Low |


### 4.3 배포 아키텍처

**설계 목표:** 동시 접속자 100명 지원, 향후 200명까지 확장 가능

#### 4.3.1 Phase 1: 단일 서버 구성 (현재)

**아키텍처:**

```
                    Internet
                        |
                   [WiFi Router]
                        |
        +---------------+----------------+
        |               |                |
   [작업 PC 1-7]   [관리자 PC]    [Primary Server]
                                         |
                         +---------------+--------------+
                         |               |              |
                    [Nginx]       [PostgreSQL]      [Redis]
                         |
                +--------+--------+
                |                 |
          [FastAPI         [FastAPI
           Worker 1]        Worker 2-8]
```

**서버 스펙 권장:**

- CPU: 8 코어 (Intel Xeon 또는 AMD EPYC)
- RAM: 32GB
- SSD: 500GB (NVMe)
- 네트워크: 1Gbps
- OS: Ubuntu 22.04 LTS

**컴포넌트 배치:**

| 컴포넌트 | 포트 | 프로세스 수 | 메모리 |
|---------|------|------------|--------|
| Nginx | 80, 443 | 1 | 512MB |
| FastAPI (Uvicorn) | 8000 | 8 workers | 4GB (총) |
| PostgreSQL | 5432 | 1 | 8GB |
| Redis | 6379 | 1 | 4GB |
| Prometheus | 9090 | 1 | 2GB |
| Grafana | 3000 | 1 | 512MB |

**연결 흐름:**

1. 클라이언트 → Nginx (443) → SSL 종단
2. Nginx → FastAPI (8000) → 8개 worker에 분산
3. FastAPI → PostgreSQL (5432) → Connection Pool (50 connections)
4. FastAPI → Redis (6379) → 캐시 조회/저장


### 4.4 네트워크 구성

| 구분 | IP 주소 | 용도 | 포트 |
|------|---------|------|------|
| WiFi 공유기 | 192.168.1.1 | Gateway | - |
| MES 서버 | 192.168.1.10 | MES 서버 | 80, 443, 5432, 6379 |
| 작업 PC 1-7 | 192.168.1.101-107 | 공정별 | - |
| 관리자 PC | 192.168.1.201-230 | 대시보드 접속 | - |
| 프린터 | 192.168.1.50-57 | 라벨 프린터 | 9100 (TCP) |

**네트워크 대역폭 산정:**

```
동시 접속자: 100명
평균 API 요청 크기: 5KB (Request) + 20KB (Response) = 25KB
요청 빈도: 10초당 1회 (0.1 req/s per user)

총 대역폭 = 100명 × 0.1 req/s × 25KB = 250KB/s = 2Mbps

피크 시간대 (×5 배수): 10Mbps
권장 네트워크: 1Gbps (여유율 100배)
```


### 4.5 AWS 클라우드 마이그레이션 전략

#### 4.5.1 코드 수정 최소화 원칙

본 시스템은 온프레미스 환경에서 개발되지만, 향후 AWS로의 마이그레이션을 고려하여 다음 원칙을 따라 설계합니다:

**핵심 설계 패턴:**

1. **12 Factor App 패턴**
   - 모든 환경별 설정을 환경 변수로 관리
   - 하드코딩된 설정 금지 (IP, 포트, 경로 등)
   - 개발/스테이징/프로덕션/AWS 환경 동일 코드 사용

2. **Storage Adapter 패턴**
   - 파일 저장소 추상화 (로컬 vs S3)
   - 인터페이스 기반 설계로 구현체만 교체
   - 펌웨어, 백업 파일 등에 적용

3. **Docker 컨테이너화**
   - 환경 독립적인 배포 패키지
   - 온프레미스와 AWS에서 동일 이미지 사용
   - 환경 변수만 변경하여 배포

**코드 수정 목표:** 0-10 라인 (환경 변수 파일만 수정)

#### 4.5.2 환경별 설정 관리

**config.py 구조:**

```python
# backend/app/core/config.py
import os
from typing import Optional

class Settings:
    """환경 변수 기반 설정 관리"""

    # 데이터베이스
    DATABASE_URL: str = os.getenv(
        "DATABASE_URL",
        "postgresql://neurohub:password@localhost:5432/neurohub"
    )

    # Redis 캐시
    REDIS_URL: str = os.getenv(
        "REDIS_URL",
        "redis://localhost:6379/0"
    )

    # 스토리지 설정
    USE_S3: bool = os.getenv("USE_S3", "false").lower() == "true"
    S3_BUCKET: Optional[str] = os.getenv("S3_BUCKET", None)
    AWS_REGION: str = os.getenv("AWS_REGION", "ap-northeast-2")

    # 로컬 파일 경로 (온프레미스 전용)
    FIRMWARE_DIR: str = os.getenv("FIRMWARE_DIR", "/app/data/firmware")
    BACKUP_DIR: str = os.getenv("BACKUP_DIR", "/app/data/backups")

    # 애플리케이션
    API_HOST: str = os.getenv("API_HOST", "0.0.0.0")
    API_PORT: int = int(os.getenv("API_PORT", "8000"))

    # 보안
    SECRET_KEY: str = os.getenv("SECRET_KEY", "dev-secret-key-change-in-production")
    JWT_ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", "30"))

settings = Settings()
```

**환경별 설정 파일:**

온프레미스 환경 (`.env.onprem`):
```bash
DATABASE_URL=postgresql://neurohub:password@192.168.1.10:5432/neurohub
REDIS_URL=redis://192.168.1.10:6379/0
USE_S3=false
FIRMWARE_DIR=/app/data/firmware
BACKUP_DIR=/app/data/backups
API_HOST=0.0.0.0
API_PORT=8000
SECRET_KEY=your-production-secret-key
```

AWS 환경 (`.env.aws`):
```bash
DATABASE_URL=postgresql://admin:password@neurohub.abc123.ap-northeast-2.rds.amazonaws.com:5432/neurohub
REDIS_URL=redis://neurohub.abc123.apn2.cache.amazonaws.com:6379/0
USE_S3=true
S3_BUCKET=neurohub-firmware-prod
AWS_REGION=ap-northeast-2
API_HOST=0.0.0.0
API_PORT=8000
SECRET_KEY=your-aws-production-secret-key
```

#### 4.5.3 Storage Adapter 구현

**스토리지 추상화 인터페이스:**

```python
# backend/app/services/storage.py
from abc import ABC, abstractmethod
from pathlib import Path
from typing import BinaryIO

class StorageAdapter(ABC):
    """파일 저장소 추상 인터페이스"""

    @abstractmethod
    def upload(self, file_path: str, key: str) -> str:
        """파일 업로드"""
        pass

    @abstractmethod
    def download(self, key: str, file_path: str) -> None:
        """파일 다운로드"""
        pass

    @abstractmethod
    def exists(self, key: str) -> bool:
        """파일 존재 여부 확인"""
        pass

    @abstractmethod
    def delete(self, key: str) -> None:
        """파일 삭제"""
        pass

    @abstractmethod
    def get_url(self, key: str) -> str:
        """파일 URL 반환"""
        pass


class LocalStorage(StorageAdapter):
    """로컬 파일 시스템 저장소 (온프레미스)"""

    def __init__(self, base_dir: str):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)

    def upload(self, file_path: str, key: str) -> str:
        import shutil
        dest = self.base_dir / key
        dest.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy(file_path, dest)
        return str(dest)

    def download(self, key: str, file_path: str) -> None:
        import shutil
        src = self.base_dir / key
        shutil.copy(src, file_path)

    def exists(self, key: str) -> bool:
        return (self.base_dir / key).exists()

    def delete(self, key: str) -> None:
        (self.base_dir / key).unlink(missing_ok=True)

    def get_url(self, key: str) -> str:
        return f"/api/v1/files/{key}"


class S3Storage(StorageAdapter):
    """AWS S3 저장소 (클라우드)"""

    def __init__(self, bucket: str, region: str):
        import boto3
        self.bucket = bucket
        self.region = region
        self.s3 = boto3.client('s3', region_name=region)

    def upload(self, file_path: str, key: str) -> str:
        self.s3.upload_file(file_path, self.bucket, key)
        return f"s3://{self.bucket}/{key}"

    def download(self, key: str, file_path: str) -> None:
        self.s3.download_file(self.bucket, key, file_path)

    def exists(self, key: str) -> bool:
        try:
            self.s3.head_object(Bucket=self.bucket, Key=key)
            return True
        except:
            return False

    def delete(self, key: str) -> None:
        self.s3.delete_object(Bucket=self.bucket, Key=key)

    def get_url(self, key: str) -> str:
        # Presigned URL (7일 유효)
        return self.s3.generate_presigned_url(
            'get_object',
            Params={'Bucket': self.bucket, 'Key': key},
            ExpiresIn=604800  # 7 days
        )


# Factory: 환경에 따라 자동 선택
def get_storage() -> StorageAdapter:
    """환경별 스토리지 어댑터 생성"""
    from app.core.config import settings

    if settings.USE_S3:
        return S3Storage(settings.S3_BUCKET, settings.AWS_REGION)
    else:
        return LocalStorage(settings.FIRMWARE_DIR)
```

**사용 예시 (펌웨어 관리):**

```python
# backend/app/api/v1/endpoints/firmware.py
from app.services.storage import get_storage

@router.post("/upload")
async def upload_firmware(file: UploadFile):
    storage = get_storage()  # 환경에 따라 자동 선택

    # 임시 파일로 저장
    temp_path = f"/tmp/{file.filename}"
    with open(temp_path, "wb") as f:
        f.write(await file.read())

    # 스토리지에 업로드 (로컬 or S3)
    key = f"firmware/{file.filename}"
    storage.upload(temp_path, key)

    return {"message": "Uploaded", "key": key}

@router.get("/download/{version}")
async def download_firmware(version: str):
    storage = get_storage()

    # 다운로드 URL 생성 (로컬: /api/v1/files/xxx, S3: presigned URL)
    key = f"firmware/firmware_{version}.bin"
    url = storage.get_url(key)

    return {"download_url": url}
```

#### 4.5.4 AWS 마이그레이션 옵션

**Option 1: Lift & Shift (EC2 기반)**

| 항목 | 내용 |
|------|------|
| **난이도** | ⭐⭐ (쉬움) |
| **마이그레이션 시간** | 1-2일 |
| **코드 수정** | 0-10 라인 (환경 변수만) |
| **예상 비용** | ~$252/월 |
| **장점** | 빠른 마이그레이션, 최소 변경 |
| **단점** | 운영 부담 높음, HA 수동 구성 |

**AWS 구성:**
- EC2 t3.large (2개: primary + standby)
- PostgreSQL: EC2에 설치
- Redis: EC2에 설치
- 로드밸런서: Nginx (EC2 내부)
- 파일 스토리지: EBS 볼륨

**배포 방법:**
```bash
# 1. Docker Compose로 배포
docker-compose -f docker-compose.aws.yml up -d

# 2. 환경 변수만 변경
export DATABASE_URL=postgresql://...
export REDIS_URL=redis://...
export USE_S3=false
```


**Option 2: Managed Services (권장)**

| 항목 | 내용 |
|------|------|
| **난이도** | ⭐⭐⭐ (보통) |
| **마이그레이션 시간** | 3-4주 |
| **코드 수정** | 0 라인 (환경 변수만) |
| **예상 비용** | ~$427/월 |
| **장점** | 자동 백업, 자동 HA, 모니터링 통합 |
| **단점** | 초기 설정 복잡, 비용 높음 |

**AWS 서비스 매핑:**

| 온프레미스 | AWS 서비스 | 설정 |
|-----------|-----------|------|
| PostgreSQL 15 | RDS PostgreSQL 15 | db.t3.large (Multi-AZ) |
| Redis 7.x | ElastiCache Redis | cache.t3.medium (Cluster 모드) |
| Nginx | Application Load Balancer (ALB) | HTTP/HTTPS 리스너 |
| 파일 저장소 | S3 | Standard Storage Class |
| 백업 | S3 + RDS Snapshot | 자동 백업 (7일 보관) |
| 모니터링 | CloudWatch | RDS/EC2 통합 메트릭 |
| 로그 | CloudWatch Logs | 중앙 집중식 로그 |

**인프라 구성 (Terraform):**

```hcl
# infrastructure/aws/main.tf
resource "aws_db_instance" "neurohub" {
  identifier           = "neurohub-postgres"
  engine               = "postgres"
  engine_version       = "15.4"
  instance_class       = "db.t3.large"
  allocated_storage    = 100
  storage_type         = "gp3"

  multi_az             = true  # 고가용성
  backup_retention_period = 7

  db_name              = "neurohub"
  username             = "admin"
  password             = var.db_password

  vpc_security_group_ids = [aws_security_group.db.id]
}

resource "aws_elasticache_cluster" "neurohub" {
  cluster_id           = "neurohub-redis"
  engine               = "redis"
  engine_version       = "7.0"
  node_type            = "cache.t3.medium"
  num_cache_nodes      = 2
  parameter_group_name = "default.redis7"

  subnet_group_name    = aws_elasticache_subnet_group.neurohub.name
  security_group_ids   = [aws_security_group.cache.id]
}

resource "aws_s3_bucket" "firmware" {
  bucket = "neurohub-firmware-prod"

  versioning {
    enabled = true
  }

  lifecycle_rule {
    enabled = true
    expiration {
      days = 90  # 90일 후 자동 삭제
    }
  }
}
```

#### 4.5.5 단계별 마이그레이션 절차

**Phase 1: 준비 단계 (1주)**

1. **AWS 계정 설정**
   - AWS 계정 생성
   - IAM 사용자 및 역할 설정
   - VPC 및 서브넷 구성 (Private/Public)

2. **코드 검증**
   - 환경 변수 기반 설정 확인
   - Storage Adapter 테스트
   - Docker 이미지 빌드 및 테스트

3. **데이터 마이그레이션 계획**
   - PostgreSQL 덤프 생성
   - 데이터 크기 산정
   - 마이그레이션 다운타임 계획

**Phase 2: 인프라 구축 (1-2주)**

1. **AWS 리소스 프로비저닝**
   ```bash
   cd infrastructure/aws
   terraform init
   terraform plan
   terraform apply
   ```

2. **데이터베이스 마이그레이션**
   ```bash
   # 온프레미스에서 덤프 생성
   pg_dump -h 192.168.1.10 -U neurohub neurohub > neurohub_backup.sql

   # AWS RDS로 복원
   psql -h neurohub.abc123.ap-northeast-2.rds.amazonaws.com \
        -U admin -d neurohub < neurohub_backup.sql
   ```

3. **파일 마이그레이션 (펌웨어)**
   ```bash
   # AWS CLI로 S3 동기화
   aws s3 sync /app/data/firmware/ s3://neurohub-firmware-prod/firmware/
   ```

**Phase 3: 배포 및 전환 (3-5일)**

1. **애플리케이션 배포**
   ```bash
   # Docker 이미지 ECR에 푸시
   docker tag neurohub-backend:latest 123456789.dkr.ecr.ap-northeast-2.amazonaws.com/neurohub-backend:latest
   docker push 123456789.dkr.ecr.ap-northeast-2.amazonaws.com/neurohub-backend:latest

   # EC2에서 실행
   docker-compose -f docker-compose.aws.yml up -d
   ```

2. **환경 변수 설정**
   ```bash
   # .env.aws 파일 생성
   DATABASE_URL=postgresql://admin:password@neurohub.abc123.ap-northeast-2.rds.amazonaws.com:5432/neurohub
   REDIS_URL=redis://neurohub.abc123.apn2.cache.amazonaws.com:6379/0
   USE_S3=true
   S3_BUCKET=neurohub-firmware-prod
   AWS_REGION=ap-northeast-2
   ```

3. **DNS 전환**
   - Route 53에 도메인 등록
   - ALB DNS를 A 레코드로 연결
   - 점진적 트래픽 전환 (0% → 10% → 50% → 100%)

**Phase 4: 검증 및 최적화 (1주)**

1. **성능 테스트**
   - API 응답 시간 측정
   - 데이터베이스 쿼리 최적화
   - 캐시 히트율 확인

2. **모니터링 설정**
   - CloudWatch 대시보드 구성
   - 알람 설정 (CPU, 메모리, 디스크, API 에러율)
   - 로그 확인 및 분석

3. **백업 검증**
   - RDS 자동 스냅샷 확인
   - S3 버킷 버전 관리 테스트
   - 복원 절차 문서화

#### 4.5.6 비용 산정

**온프레미스 vs AWS 비용 비교 (월간):**

| 구분 | 온프레미스 | AWS (Lift & Shift) | AWS (Managed) |
|------|-----------|-------------------|--------------|
| **서버** | ~$3,000 (초기 투자) | EC2 t3.large × 2: $120 | EC2 t3.large × 2: $120 |
| **데이터베이스** | 포함 | 포함 (EC2) | RDS db.t3.large (Multi-AZ): $240 |
| **캐시** | 포함 | 포함 (EC2) | ElastiCache t3.medium: $50 |
| **스토리지** | HDD 2TB: $100 | EBS 100GB: $10 | S3 50GB: $1.15 |
| **네트워크** | 사내망 무료 | 데이터 전송: $20 | ALB: $25 + 데이터 전송: $20 |
| **백업** | 외장 HDD: $50 | EBS 스냅샷: $5 | 포함 (RDS 자동 백업) |
| **인건비** | 시스템 관리자 필요 | 부분 관리 필요 | 최소 관리 |
| **총 월간 비용** | ~$150 + 인건비 | ~$252 | ~$427 |

**3년 총 소유 비용 (TCO):**

| 항목 | 온프레미스 | AWS (Managed) |
|------|-----------|--------------|
| 초기 투자 | $3,000 (서버 구매) | $0 |
| 운영 비용 (3년) | $5,400 ($150×36) | $15,372 ($427×36) |
| 인건비 (3년) | $36,000 (시스템 관리자) | $12,000 (부분 관리) |
| **총계** | **$44,400** | **$27,372** |

**결론:** AWS Managed Services가 3년 기준 약 $17,000 절감 (38% 저렴)

#### 4.5.7 롤백 계획

AWS 마이그레이션 실패 시 온프레미스로 복귀하는 절차:

1. **DNS 복원** (5분)
   - Route 53에서 온프레미스 IP로 A 레코드 변경
   - TTL이 짧으므로 5분 내 전환

2. **데이터 동기화** (1-2시간)
   ```bash
   # AWS RDS에서 최신 데이터 덤프
   pg_dump -h neurohub.abc123.ap-northeast-2.rds.amazonaws.com \
           -U admin neurohub > latest_backup.sql

   # 온프레미스 DB 복원
   psql -h 192.168.1.10 -U neurohub neurohub < latest_backup.sql
   ```

3. **환경 변수 복원**
   ```bash
   # .env.onprem 파일 재적용
   docker-compose -f docker-compose.onprem.yml up -d
   ```

4. **검증**
   - API 헬스체크 확인
   - 주요 기능 테스트 (LOT 생성, 공정 완공 등)

**최대 다운타임:** 2-3시간 (데이터 동기화 시간 포함)

---

## 5. 데이터 설계

### 5.1 핵심 엔티티 관계도 (ERD)

```mermaid
erDiagram
    PRODUCT_MODELS ||--o{ LOTS : has
    LOTS ||--o{ SERIALS : contains
    LOTS ||--o{ PROCESS_DATA : records
    SERIALS ||--o{ PROCESS_DATA : tracks
    PROCESSES ||--o{ PROCESS_DATA : defines

    PRODUCT_MODELS {
        int id PK
        string model_code UK
        string model_name
        string description
    }

    LOTS {
        bigint id PK
        string lot_number UK
        int product_model_id FK
        int target_quantity
        string shift
        string status
        datetime created_at
    }

    SERIALS {
        bigint id PK
        string serial_number UK
        bigint lot_id FK
        int sequence
        string status
        datetime created_at
    }

    PROCESSES {
        int id PK
        string process_code UK
        string process_name
        int sequence_order
    }

    PROCESS_DATA {
        bigint id PK
        bigint lot_id FK
        bigint serial_id FK
        int process_id FK
        jsonb process_specific_data
        datetime start_time
        datetime complete_time
    }
```

### 5.2 데이터베이스 스키마 상세

#### 5.2.1 스키마 생성 스크립트

다음은 PostgreSQL 기준 CREATE TABLE 문입니다.

**product_models 테이블:**

```sql
CREATE TABLE product_models (
    id BIGSERIAL PRIMARY KEY,
    model_code VARCHAR(50) UNIQUE NOT NULL,
    model_name VARCHAR(200) NOT NULL,
    description TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_product_models_code ON product_models(model_code);
```

**lots 테이블:**

```sql
CREATE TABLE lots (
    id BIGSERIAL PRIMARY KEY,
    lot_number VARCHAR(50) UNIQUE NOT NULL,
    product_model_id BIGINT REFERENCES product_models(id) ON DELETE RESTRICT,
    target_quantity INTEGER DEFAULT 100 CHECK (target_quantity > 0),
    shift CHAR(1) CHECK (shift IN ('D', 'N')),
    status VARCHAR(20) DEFAULT 'CREATED' CHECK (status IN ('CREATED', 'IN_PROGRESS', 'COMPLETED', 'CLOSED')),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    completed_at TIMESTAMP WITH TIME ZONE,
    closed_at TIMESTAMP WITH TIME ZONE
);

CREATE INDEX idx_lot_number ON lots(lot_number);
CREATE INDEX idx_lot_created_at ON lots(created_at DESC);
CREATE INDEX idx_lot_status ON lots(status);
CREATE INDEX idx_lot_product_model ON lots(product_model_id);
```

**serials 테이블:**

```sql
CREATE TABLE serials (
    id BIGSERIAL PRIMARY KEY,
    serial_number VARCHAR(100) UNIQUE NOT NULL,
    lot_id BIGINT REFERENCES lots(id) ON DELETE RESTRICT,
    sequence INTEGER NOT NULL CHECK (sequence > 0 AND sequence <= 100),
    status VARCHAR(20) DEFAULT 'CREATED' CHECK (status IN ('CREATED', 'IN_PROGRESS', 'PASSED', 'FAILED')),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(lot_id, sequence)
);

CREATE INDEX idx_serial_number ON serials(serial_number);
CREATE INDEX idx_serial_lot ON serials(lot_id);
CREATE INDEX idx_serial_status ON serials(status);
```

**processes 테이블:**

```sql
CREATE TABLE processes (
    id BIGSERIAL PRIMARY KEY,
    process_id VARCHAR(20) UNIQUE NOT NULL,
    process_name VARCHAR(100) NOT NULL,
    sequence_order INTEGER NOT NULL,
    description TEXT,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_process_id ON processes(process_id);
CREATE INDEX idx_process_sequence ON processes(sequence_order);
```

**process_data 테이블:**

```sql
CREATE TABLE process_data (
    id BIGSERIAL PRIMARY KEY,
    lot_id BIGINT REFERENCES lots(id) ON DELETE RESTRICT,
    serial_id BIGINT REFERENCES serials(id) ON DELETE RESTRICT,
    process_id BIGINT REFERENCES processes(id) ON DELETE RESTRICT,
    line_id VARCHAR(50) NOT NULL,
    equipment_id VARCHAR(50) NOT NULL,
    worker_id VARCHAR(50),
    process_specific_data JSONB,
    start_time TIMESTAMP WITH TIME ZONE NOT NULL,
    complete_time TIMESTAMP WITH TIME ZONE,
    result VARCHAR(20) CHECK (result IN ('PASS', 'FAIL', 'PENDING')),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_process_data_lot ON process_data(lot_id);
CREATE INDEX idx_process_data_serial ON process_data(serial_id);
CREATE INDEX idx_process_data_process ON process_data(process_id);
CREATE INDEX idx_process_data_line ON process_data(line_id);
CREATE INDEX idx_process_data_equipment ON process_data(equipment_id);
CREATE INDEX idx_process_data_time ON process_data(start_time DESC);
CREATE INDEX idx_process_data_jsonb ON process_data USING GIN (process_specific_data);
```

**users 테이블:**

```sql
CREATE TABLE users (
    id BIGSERIAL PRIMARY KEY,
    user_id VARCHAR(50) UNIQUE NOT NULL,
    username VARCHAR(100) NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    role VARCHAR(20) DEFAULT 'WORKER' CHECK (role IN ('ADMIN', 'MANAGER', 'WORKER')),
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_user_id ON users(user_id);
CREATE INDEX idx_user_role ON users(role);
```

**audit_logs 테이블 (감사 로그):**

```sql
CREATE TABLE audit_logs (
    id BIGSERIAL PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    record_id BIGINT,
    action VARCHAR(20) NOT NULL CHECK (action IN ('INSERT', 'UPDATE', 'DELETE')),
    user_id VARCHAR(50),
    old_data JSONB,
    new_data JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_audit_table ON audit_logs(table_name);
CREATE INDEX idx_audit_time ON audit_logs(created_at DESC);
CREATE INDEX idx_audit_user ON audit_logs(user_id);
```

> **참고:**
> - 모든 타임스탬프는 `TIMESTAMP WITH TIME ZONE`을 사용하여 시간대 정보를 보존합니다.
> - JSONB 인덱스(GIN)는 공정별 데이터 검색 성능을 향상시킵니다.
> - 외래 키에 `ON DELETE RESTRICT`를 사용하여 데이터 무결성을 보장합니다.

### 5.3 주요 테이블 설명

#### 5.2.1 제품 모델 (product_models)

**용도:** 제품 유형 관리

**주요 필드:**

- `model_code`: 제품 모델 코드 (예: NH-F2X-001)
- `model_name`: 제품명
- `description`: 설명


#### 5.2.2 LOT (lots)

**용도:** LOT 정보 관리

**주요 필드:**

- `lot_number`: LOT 번호 (UK)
- `product_model_id`: 제품 모델 FK
- `target_quantity`: 목표 수량 (100)
- `shift`: 교대 (D/N)
- `status`: CREATED, IN_PROGRESS, COMPLETED, CLOSED


#### 5.2.3 시리얼 번호 (serials)

**용도:** 개별 제품 추적

**주요 필드:**

- `serial_number`: 시리얼 번호 (UK)
- `lot_id`: 소속 LOT FK
- `sequence`: LOT 내 순번 (1~100)
- `status`: CREATED, IN_PROGRESS, PASSED, FAILED


#### 5.2.4 공정 데이터 (process_data)

**용도:** 공정별 작업 데이터 저장

**주요 필드:**

- `lot_id`: LOT FK
- `serial_id`: 시리얼 FK (nullable)
- `process_id`: 공정 FK
- `process_specific_data`: 공정별 데이터 (JSONB)
- `start_time`: 착공 시간
- `complete_time`: 완공 시간

**JSONB 예시:**

```json
{
  "온도": 60.5,
  "변위": 198.3,
  "힘": 15.2,
  "모선_lot": "MS-2025-100",
  "검사결과": "PASS"
}
```


### 5.3 LOT 및 시리얼 번호 체계

#### 5.3.1 LOT 번호 형식

**형식:** `{제품코드}-{공장코드}-{YYMMDD}{교대}-{일련번호}`

**예시:** `WF-KR-251110D-001`

| 요소 | 설명 | 예시 |
|------|------|------|
| 제품코드 | 제품 식별 코드 | WF |
| 공장코드 | 생산 공장 | KR |
| YYMMDD | 생산 날짜 | 251110 |
| 교대 | Day/Night | D |
| 일련번호 | 당일 순번 | 001 |


#### 5.3.2 시리얼 번호 형식

**형식:** `{LOT번호}-{순번}`

**예시:** `WF-KR-251110D-001-0001`

- LOT당 0001~0100 (100개)
- Label Printing 공정에서 순차 생성


## 6. 개발 및 투자 계획

### 6.1 개발 일정

**Phase 1: MVP (8주)**

| 주차 | 작업 내용 |
|------|----------|
| 1주 | 환경 설정, DB 설계, API 설계 |
| 2-3주 | Backend API 개발 (LOT, 시리얼, 공정) |
| 4-5주 | Frontend App 개발 (작업 PC) |
| 6주 | Dashboard 개발 (관리자) |
| 7주 | 통합 테스트 |
| 8주 | 현장 파일럿 및 피드백 |

### 6.2 팀 구성

| 역할 | 인원 | 책임 |
|------|------|------|
| Backend 개발자 | 1-2명 | FastAPI, DB, API |
| Frontend 개발자 | 1명 | PyQt5, React |
| DevOps | 1명 | 서버, 배포, 모니터링 |

**최소 인원:** 2-3명

**권장 인원:** 3-4명


### 6.3 투자 계획 (배포 옵션별 비교)

본 섹션에서는 **세 가지 배포 옵션**에 따른 투자 비용을 비교합니다. 각 옵션의 상세 비교는 **4.1 배포 옵션 비교** 참조.

#### 6.3.1 배포 옵션별 초기 투자 비용

##### Option A: 온프레미스

**하드웨어 (서버 인프라):**

| 항목 | 수량 | 단가 (만원) | 금액 (만원) |
|------|------|------------|------------|
| 백엔드 서버 (Dell PowerEdge R250) | 2 | 900 | 1,800 |
| DB 서버 (Dell PowerEdge R350) | 1 | 1,200 | 1,200 |
| 네트워크 장비 (스위치, 라우터, UPS) | 1세트 | 800 | 800 |
| 설치/구축비 (케이블링, 랙) | 1식 | 500 | 500 |
| 기타 (라이선스, 보안 솔루션) | 1식 | 685 | 685 |
| **서버 소계** | | | **4,985** |

**공통 장비 (모든 옵션 공통):**

| 항목 | 수량 | 단가 (만원) | 금액 (만원) |
|------|------|------------|------------|
| 작업 PC | 7 | 80 | 560 |
| WiFi 공유기 | 1 | 30 | 30 |
| 바코드 스캐너 | 7 | 15 | 105 |
| 라벨 프린터 (Zebra ZT) | 2 | 150 | 300 |
| **공통 장비 소계** | | | **995** |

**소프트웨어 및 개발:**

| 항목 | 금액 (만원) |
|------|------------|
| 개발 인건비 (8주) | 640 |
| 인프라 구축비 (2-3주) | 160 |
| 기타 SW 라이선스 | 10 |
| **개발 소계** | **810** |

**온프레미스 총 초기 투자:** **6,790만원**

---

##### Option B-1: Railway (Cloud PaaS)

**클라우드 인프라:**
- Railway 플랫폼 사용 (초기 비용 0원)
- 첫 달 $5 무료 크레딧

**공통 장비 (모든 옵션 공통):**

| 항목 | 수량 | 단가 (만원) | 금액 (만원) |
|------|------|------------|------------|
| 작업 PC | 7 | 80 | 560 |
| WiFi 공유기 | 1 | 30 | 30 |
| 바코드 스캐너 | 7 | 15 | 105 |
| 라벨 프린터 (Zebra ZT) | 2 | 150 | 300 |
| **공통 장비 소계** | | | **995** |

**소프트웨어 및 개발:**

| 항목 | 금액 (만원) |
|------|------------|
| 개발 인건비 (8주) | 640 |
| Railway 설정/배포 (1주) | 160 |
| 기타 SW 라이선스 | 10 |
| **개발 소계** | **810** |

**Railway 총 초기 투자:** **1,805만원**

---

##### Option B-2: AWS (Cloud IaaS)

**클라우드 인프라:**
- AWS 계정 생성 (무료)
- 초기 인프라 설정 비용 포함

**공통 장비 (모든 옵션 공통):**

| 항목 | 수량 | 단가 (만원) | 금액 (만원) |
|------|------|------------|------------|
| 작업 PC | 7 | 80 | 560 |
| WiFi 공유기 | 1 | 30 | 30 |
| 바코드 스캐너 | 7 | 15 | 105 |
| 라벨 프린터 (Zebra ZT) | 2 | 150 | 300 |
| **공통 장비 소계** | | | **995** |

**소프트웨어 및 개발:**

| 항목 | 금액 (만원) |
|------|------------|
| 개발 인건비 (8주) | 640 |
| AWS 인프라 구축 (2-3주) | 160 |
| 기타 SW 라이선스 | 10 |
| **개발 소계** | **810** |

**AWS 총 초기 투자:** **1,805만원**

---

#### 6.3.2 배포 옵션별 월 운영 비용

##### 월 운영 비용 비교표

| 항목 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **인프라 비용** | 0원 | 26만원 | 220-350만원 |
| **전기/네트워크** | 20만원 | 0원 | 0원 |
| **시스템 관리** | 50만원 (파트타임) | 0원 | 30만원 (모니터링) |
| **백업/모니터링** | 23만원 | 0원 (Railway 포함) | 10만원 |
| **기타 소모품** | 20만원 | 0원 | 5만원 |
| **월 합계** | **113만원** | **26만원** | **265-395만원** |

**상세 내역:**

**온프레미스 (월 113만원):**
- 전기료: 20만원/월 (서버 3대 24시간 가동)
- 시스템 관리자: 50만원/월 (파트타임, 주 2-3일)
- 백업/모니터링 툴: 23만원/월
- 기타 소모품: 20만원/월

**Railway (월 26만원):**
- Hobby Plan: $20/월 (약 26만원)
- PostgreSQL, Redis, 백엔드 모두 포함
- 자동 백업, 모니터링 포함
- 추가 비용 없음

**AWS (월 265-395만원):**
- EC2 t3.medium (2대): $60/월 (78만원)
- RDS PostgreSQL db.t3.medium: $80/월 (104만원)
- ElastiCache Redis t3.micro: $15/월 (19.5만원)
- S3 Storage (100GB): $3/월 (3.9만원)
- Data Transfer: $50-180/월 (65-234만원, 트래픽에 따라 변동)
- CloudWatch 모니터링: $10/월 (13만원)
- **합계:** $218-348/월 (약 283-452만원)
- **평균:** 약 **330만원/월** (중간값 기준)

#### 6.3.3 총 소유 비용 (TCO) 비교

##### 3년 TCO 비교표

| 구분 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **초기 투자** | 6,790만원 | 1,805만원 | 1,805만원 |
| **36개월 운영비** | 4,068만원 (113만원×36) | 936만원 (26만원×36) | 11,880만원 (330만원×36) |
| **3년 총 비용** | **10,858만원** | **2,741만원** | **13,685만원** |
| **월평균 비용** | 302만원 | 76만원 | 380만원 |

##### 5년 TCO 비교표

| 구분 | 온프레미스 | Railway | AWS |
|------|-----------|---------|-----|
| **초기 투자** | 6,790만원 | 1,805만원 | 1,805만원 |
| **60개월 운영비** | 6,780만원 (113만원×60) | 1,560만원 (26만원×60) | 19,800만원 (330만원×60) |
| **5년 총 비용** | **13,570만원** | **3,365만원** | **21,605만원** |
| **월평균 비용** | 226만원 | 56만원 | 360만원 |

**TCO 분석 인사이트:**

- **Railway가 모든 기간에서 가장 저렴** (3년: 2,741만원, 5년: 3,365만원)
- **온프레미스는 장기 운영 시 유리** (초기 투자 높지만 월 비용 낮음)
- **AWS는 총 비용이 가장 높음** (엔터프라이즈급 안정성과 확장성 제공)
- **손익분기점:**
  - Railway vs 온프레미스: 약 60개월 (5년)
  - AWS vs 온프레미스: AWS가 모든 기간에서 더 비쌈

#### 6.3.4 의사결정 가이드

**초기 투자 여력이 부족한 경우:**
- Railway (초기 1,805만원, 월 26만원)

**장기 운영 계획 (5년 이상):**
- 온프레미스 (5년 TCO 13,570만원)

**엔터프라이즈급 안정성 필요:**
- AWS (초기 1,805만원, 월 330만원)

**빠른 시작이 중요한 경우:**
- Railway (8주 배포)

**데이터 보안이 최우선:**
- 온프레미스 (자체 서버실)


### 6.4 ROI 분석

**기대 효과 (연간):**

| 항목 | 절감/효과 | 금액 (만원/년) |
|------|-----------|---------------|
| 불량 원인 파악 시간 단축 | 월 20시간 절감 | 600 |
| 재고 관리 효율화 | 과잉 재고 감소 | 1,000 |
| 생산 계획 최적화 | 가동률 5% 향상 | 2,000 |
| **합계** | | **3,600** |

**회수 기간:** 약 1.4년

### 6.5 리스크 관리

#### 6.5.1 주요 리스크 및 대응 방안

| 리스크 | 발생 가능성 | 영향도 | 대응 방안 | 담당자 |
|--------|------------|--------|----------|--------|
| **외부 공정 앱 연동 실패** | 중 | 높음 | - 초기 POC 단계에서 File Watcher 검증<br>- 대체 HTTP API 연동 준비<br>- 외부 업체와 긴밀한 협업 체계 구축 | Backend 개발자 |
| **라벨 프린터 호환성 문제** | 높음 | 중 | - 프린터 3종 이상 지원 (Zebra, TSC, Godex)<br>- ZPL/ESC-POS 명령어 추상화 레이어 구현<br>- 현장 프린터 사전 테스트 | Frontend 개발자 |
| **네트워크 불안정** | 낮음 | 높음 | - 로컬 SQLite 백업 기능 구현<br>- 자동 재시도 로직 (최대 3회)<br>- 오프라인 모드 지원 (로컬 큐잉) | Backend/Frontend |
| **개발 일정 지연** | 중 | 중 | - MVP 범위 축소 (고급 대시보드 기능 제외)<br>- 주간 스프린트 리뷰로 진행 상황 점검<br>- 예비 개발자 확보 | PM |
| **데이터베이스 성능 저하** | 낮음 | 중 | - 인덱스 최적화 (공정별 데이터 JSONB GIN 인덱스)<br>- 쿼리 성능 모니터링 (pg_stat_statements)<br>- Connection Pool 설정 최적화 | Backend/DevOps |
| **사용자 저항** | 중 | 중 | - 현장 작업자 대상 사전 교육 (2회)<br>- 직관적인 UI/UX 설계<br>- 단계적 도입 (파일럿 → 전체 적용) | PM/교육 담당 |
| **서버 하드웨어 장애** | 낮음 | 높음 | - 일일 전체 백업 + 6시간 증분 백업<br>- NAS 백업 및 클라우드 이중 백업<br>- 예비 서버 준비 | DevOps |
| **보안 취약점** | 낮음 | 높음 | - JWT 토큰 만료 시간 설정 (1시간)<br>- HTTPS 통신 강제<br>- SQL Injection 방어 (ORM 사용)<br>- 정기 보안 점검 (월 1회) | Backend/DevOps |

#### 6.5.2 비상 대응 절차

**시스템 장애 발생 시:**

1. **즉시 대응** (10분 이내)
   - 장애 감지 및 담당자 알림 (Slack/Email)
   - 현장 작업 중단 여부 결정
   - 장애 원인 1차 파악 (로그 확인)

2. **복구 작업** (30분 이내)
   - 서버 재시작 또는 백업 서버 전환
   - 네트워크 연결 확인
   - 데이터베이스 무결성 검증

3. **서비스 재개** (1시간 이내)
   - 주요 기능 테스트 (LOT 생성, 공정 완공)
   - 현장 작업 재개 공지
   - 장애 기록 및 원인 분석 보고서 작성

**데이터 손실 발생 시:**

1. **백업 복구**
   - 최근 백업 시점 확인
   - 백업 데이터 무결성 검증
   - 데이터베이스 복원 (테스트 환경 → 프로덕션)

2. **수동 데이터 복구**
   - 로그 파일에서 트랜잭션 재구성
   - 현장 작업자 기록 확인
   - 복구 불가능 데이터 명세 작성

> **중요:** 모든 장애 상황은 장애 보고서로 문서화하여 향후 재발 방지에 활용합니다.

#### 6.5.3 변경 관리 프로세스

**요구사항 변경 절차:**

1. **변경 요청 제출**
   - 생산팀 또는 품질팀에서 변경 요청서 작성
   - 변경 사유 및 예상 효과 명시

2. **영향도 분석** (2일 이내)
   - 개발팀에서 기술적 영향도 분석
   - 개발 공수 산정
   - 일정 및 비용 영향 평가

3. **승인/반려 결정**
   - 프로젝트 관리자 및 경영진 검토
   - 우선순위 설정 (P0-긴급, P1-높음, P2-보통, P3-낮음)

4. **개발 및 배포**
   - 개발 → 단위 테스트 → 통합 테스트
   - 스테이징 환경 배포 → 검증
   - 프로덕션 배포 (야간 또는 주말)

5. **문서 업데이트**
   - 사양서 및 매뉴얼 갱신
   - 변경 이력 기록 (버전 관리)

**긴급 패치 프로세스:**

- Hot-fix 브랜치 생성 (`hotfix/v1.0.1`)
- 수정 → 단위 테스트
- 스테이징 배포 → 최소 검증
- 프로덕션 긴급 배포 (다운타임 최소화)
- 사후 보고서 작성 (24시간 이내)

---

## 7. 부록

### 7.1 용어 정의

| 용어 | 설명 |
|------|------|
| **LOT** | 동일 조건으로 생산된 제품 묶음 단위 (통상 100개) |
| **시리얼 번호** | 개별 제품 고유 식별 번호 (Serial Number) |
| **작업대차** | LOT 단위로 제품을 이동/보관하는 이동식 작업대 |
| **착공** | 공정 작업 시작 |
| **완공** | 공정 작업 완료 |
| **Traceability** | 추적성 - 제품 이력 추적 능력 |
| **MES** | Manufacturing Execution System - 제조 실행 시스템 |
| **LMA** | Linear Muscle Actuator - 로봇의 핵심 구동기 |
| **SMA 스프링** | Shape Memory Alloy 스프링 - 온도로 형상 기억하여 구동 |
| **모선** | SMA 스프링을 제조하는 원재료 케이블 |
| **EOL 검사** | End Of Line 검사 - 최종 성능 검사 |
| **TOF 센서** | Time Of Flight 센서 - 거리 측정 센서 |
| **교대조** | 작업 교대 (D: Day, N: Night) |
| **바코드 스캔** | LOT 번호/시리얼 번호 자동 인식 방식 |
| **File Watcher** | 특정 디렉토리의 파일 생성/변경을 자동 감시하는 기능 |
| **JSONB** | PostgreSQL의 JSON 이진 저장 타입 - 검색/인덱싱 최적화 |
| **API** | Application Programming Interface - 시스템 간 데이터 통신 인터페이스 |
| **JWT** | JSON Web Token - 사용자 인증용 토큰 |
| **RBAC** | Role-Based Access Control - 역할 기반 접근 제어 |
| **HA** | High Availability - 고가용성 (시스템 이중화) |
| **VIP** | Virtual IP - 가상 IP 주소 (이중화 환경용) |
| **Connection Pool** | 데이터베이스 연결 재사용 메커니즘 (성능 최적화) |
| **TPS** | Transactions Per Second - 초당 트랜잭션 처리량 |
| **TTL** | Time To Live - 데이터 유효 시간 |
| **Presigned URL** | 임시 접근 권한이 부여된 URL (S3 다운로드용) |
| **Failover** | 주 시스템 장애 시 대기 시스템으로 자동 전환 |
| **MD5 Hash** | 파일 무결성 검증용 체크섬 |
| **Streaming Replication** | PostgreSQL 실시간 데이터 복제 방식 |
| **Railway** | Cloud PaaS 플랫폼 - 간단한 배포와 자동 인프라 관리 제공 |
| **PaaS** | Platform as a Service - 플랫폼형 클라우드 서비스 |
| **IaaS** | Infrastructure as a Service - 인프라형 클라우드 서비스 |
| **AWS** | Amazon Web Services - 아마존 클라우드 플랫폼 |
| **EC2** | Elastic Compute Cloud - AWS 가상 서버 서비스 |
| **RDS** | Relational Database Service - AWS 관리형 데이터베이스 서비스 |
| **ElastiCache** | AWS 관리형 Redis/Memcached 서비스 |
| **S3** | Simple Storage Service - AWS 객체 스토리지 서비스 |
| **ALB** | Application Load Balancer - AWS 로드 밸런서 |
| **ACM** | AWS Certificate Manager - SSL/TLS 인증서 관리 서비스 |
| **VPC** | Virtual Private Cloud - AWS 가상 네트워크 |
| **CloudWatch** | AWS 모니터링 및 로깅 서비스 |
| **12-Factor App** | 클라우드 네이티브 애플리케이션 설계 원칙 (환경 변수 기반 설정 등) |
| **TCO** | Total Cost of Ownership - 총 소유 비용 (초기 투자 + 운영 비용) |
| **온프레미스** | On-Premise - 자체 서버실에 구축하는 배포 방식 |


### 7.2 문서 버전 이력

| 버전 | 날짜 | 변경 내용 | 작성자 |
|------|------|-----------|--------|
| v1.0 | 2025.11.09 | 초기 버전 | - |
| v1.6 | 2025.11.09 | 투자 목록 추가 | - |
| **v2.0** | **2025.11.10** | **전면 재작성 - 사양서 중심** | **Claude** |


### 7.3 참고 자료

- FastAPI 공식 문서: https://fastapi.tiangolo.com
- PostgreSQL 공식 문서: https://www.postgresql.org/docs/
- React 공식 문서: https://react.dev


**문서 끝**
